{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BikeSharing_Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Xznj3qACZkh7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bike Sharing Project with Pytorch\n",
        "## Udacity/ Facebook 2019"
      ]
    },
    {
      "metadata": {
        "id": "AmSOVnXkZGzz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this **project**, we'll build our first neural network and use it to predict daily bike rental ridership. "
      ]
    },
    {
      "metadata": {
        "id": "OJQyEfj3NO4X",
        "colab_type": "code",
        "outputId": "98616bdb-cf70-4631-87b7-058cec123d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Importing modules\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bze23qGCaDdh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load and prepare the data\n",
        "\n",
        "A critical step in working with neural networks is preparing the data correctly. Variables on different scales make it difficult for the network to efficiently learn the correct weights. Below, we've written the code to load and prepare the data."
      ]
    },
    {
      "metadata": {
        "id": "wrPOdbvFaNkB",
        "colab_type": "code",
        "outputId": "268af684-5cec-433d-d2d1-075cb6de1591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "data_path = 'hour.csv'\n",
        "\n",
        "rides = pd.read_csv(data_path)\n",
        "# Watch all columns\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "rides.head(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0896</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.3485</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
              "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
              "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
              "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
              "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
              "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
              "5        6  2011-01-01       1   0     1   5        0        6           0   \n",
              "6        7  2011-01-01       1   0     1   6        0        6           0   \n",
              "7        8  2011-01-01       1   0     1   7        0        6           0   \n",
              "8        9  2011-01-01       1   0     1   8        0        6           0   \n",
              "9       10  2011-01-01       1   0     1   9        0        6           0   \n",
              "\n",
              "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
              "0           1  0.24  0.2879  0.81     0.0000       3          13   16  \n",
              "1           1  0.22  0.2727  0.80     0.0000       8          32   40  \n",
              "2           1  0.22  0.2727  0.80     0.0000       5          27   32  \n",
              "3           1  0.24  0.2879  0.75     0.0000       3          10   13  \n",
              "4           1  0.24  0.2879  0.75     0.0000       0           1    1  \n",
              "5           2  0.24  0.2576  0.75     0.0896       0           1    1  \n",
              "6           1  0.22  0.2727  0.80     0.0000       2           0    2  \n",
              "7           1  0.20  0.2576  0.86     0.0000       1           2    3  \n",
              "8           1  0.24  0.2879  0.75     0.0000       1           7    8  \n",
              "9           1  0.32  0.3485  0.76     0.0000       8           6   14  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "fNmFRHTmahfL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Checking out the data\n",
        "\n",
        "This dataset has the number of riders for each hour of each day from January 1 2011 to December 31 2012. The number of riders is split between casual and registered, summed up in the `cnt` column. You can see the first few rows of the data above.\n",
        "\n",
        "Below is a plot showing the number of bike riders over the first 10 days or so in the data set. (Some days don't have exactly 24 entries in the data set, so it's not exactly 10 days.) You can see the hourly rentals here. This data is pretty complicated! The weekends have lower over all ridership and there are spikes when people are biking to and from work during the week. Looking at the data above, we also have information about temperature, humidity, and windspeed, all of these likely affecting the number of riders. You'll be trying to capture all this with our model."
      ]
    },
    {
      "metadata": {
        "id": "hHe0OlmVawOB",
        "colab_type": "code",
        "outputId": "5ca43b57-a5a2-415d-e574-a9539b2fa5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "cell_type": "code",
      "source": [
        "rides[:24].plot(x='dteday', y='cnt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdd0924ecc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAukAAAH6CAYAAAC6btKjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyVpAxNkGEwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 372,
              "height": 253
            }
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gM1q4sJKa9Vd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dummy variables\n",
        "Here we have some categorical variables like season, weather, month. To include these in our model, we'll need to make binary dummy variables. This is simple to do with Pandas thanks to `get_dummies()`."
      ]
    },
    {
      "metadata": {
        "id": "1c2_LOI9bC0f",
        "colab_type": "code",
        "outputId": "7ec7d400-6558-4bef-b47e-a4272e693844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "cell_type": "code",
      "source": [
        "dummy_fields = ['season', 'weathersit', 'mnth', 'hr', 'weekday']\n",
        "for each in dummy_fields:\n",
        "    dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)\n",
        "    rides = pd.concat([rides, dummies], axis=1)\n",
        "\n",
        "fields_to_drop = ['instant', 'dteday', 'season', 'weathersit', \n",
        "                  'weekday', 'atemp', 'mnth', 'workingday', 'hr']\n",
        "data = rides.drop(fields_to_drop, axis=1)\n",
        "#data.head(10)\n",
        "data[:10]\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>yr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>temp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "      <th>season_1</th>\n",
              "      <th>season_2</th>\n",
              "      <th>season_3</th>\n",
              "      <th>season_4</th>\n",
              "      <th>weathersit_1</th>\n",
              "      <th>weathersit_2</th>\n",
              "      <th>weathersit_3</th>\n",
              "      <th>weathersit_4</th>\n",
              "      <th>mnth_1</th>\n",
              "      <th>mnth_2</th>\n",
              "      <th>mnth_3</th>\n",
              "      <th>mnth_4</th>\n",
              "      <th>mnth_5</th>\n",
              "      <th>mnth_6</th>\n",
              "      <th>mnth_7</th>\n",
              "      <th>mnth_8</th>\n",
              "      <th>mnth_9</th>\n",
              "      <th>mnth_10</th>\n",
              "      <th>mnth_11</th>\n",
              "      <th>mnth_12</th>\n",
              "      <th>hr_0</th>\n",
              "      <th>hr_1</th>\n",
              "      <th>hr_2</th>\n",
              "      <th>hr_3</th>\n",
              "      <th>hr_4</th>\n",
              "      <th>hr_5</th>\n",
              "      <th>hr_6</th>\n",
              "      <th>hr_7</th>\n",
              "      <th>hr_8</th>\n",
              "      <th>hr_9</th>\n",
              "      <th>hr_10</th>\n",
              "      <th>hr_11</th>\n",
              "      <th>hr_12</th>\n",
              "      <th>hr_13</th>\n",
              "      <th>hr_14</th>\n",
              "      <th>hr_15</th>\n",
              "      <th>hr_16</th>\n",
              "      <th>hr_17</th>\n",
              "      <th>hr_18</th>\n",
              "      <th>hr_19</th>\n",
              "      <th>hr_20</th>\n",
              "      <th>hr_21</th>\n",
              "      <th>hr_22</th>\n",
              "      <th>hr_23</th>\n",
              "      <th>weekday_0</th>\n",
              "      <th>weekday_1</th>\n",
              "      <th>weekday_2</th>\n",
              "      <th>weekday_3</th>\n",
              "      <th>weekday_4</th>\n",
              "      <th>weekday_5</th>\n",
              "      <th>weekday_6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0896</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   yr  holiday  temp   hum  windspeed  casual  registered  cnt  season_1  \\\n",
              "0   0        0  0.24  0.81     0.0000       3          13   16         1   \n",
              "1   0        0  0.22  0.80     0.0000       8          32   40         1   \n",
              "2   0        0  0.22  0.80     0.0000       5          27   32         1   \n",
              "3   0        0  0.24  0.75     0.0000       3          10   13         1   \n",
              "4   0        0  0.24  0.75     0.0000       0           1    1         1   \n",
              "5   0        0  0.24  0.75     0.0896       0           1    1         1   \n",
              "6   0        0  0.22  0.80     0.0000       2           0    2         1   \n",
              "7   0        0  0.20  0.86     0.0000       1           2    3         1   \n",
              "8   0        0  0.24  0.75     0.0000       1           7    8         1   \n",
              "9   0        0  0.32  0.76     0.0000       8           6   14         1   \n",
              "\n",
              "   season_2  season_3  season_4  weathersit_1  weathersit_2  weathersit_3  \\\n",
              "0         0         0         0             1             0             0   \n",
              "1         0         0         0             1             0             0   \n",
              "2         0         0         0             1             0             0   \n",
              "3         0         0         0             1             0             0   \n",
              "4         0         0         0             1             0             0   \n",
              "5         0         0         0             0             1             0   \n",
              "6         0         0         0             1             0             0   \n",
              "7         0         0         0             1             0             0   \n",
              "8         0         0         0             1             0             0   \n",
              "9         0         0         0             1             0             0   \n",
              "\n",
              "   weathersit_4  mnth_1  mnth_2  mnth_3  mnth_4  mnth_5  mnth_6  mnth_7  \\\n",
              "0             0       1       0       0       0       0       0       0   \n",
              "1             0       1       0       0       0       0       0       0   \n",
              "2             0       1       0       0       0       0       0       0   \n",
              "3             0       1       0       0       0       0       0       0   \n",
              "4             0       1       0       0       0       0       0       0   \n",
              "5             0       1       0       0       0       0       0       0   \n",
              "6             0       1       0       0       0       0       0       0   \n",
              "7             0       1       0       0       0       0       0       0   \n",
              "8             0       1       0       0       0       0       0       0   \n",
              "9             0       1       0       0       0       0       0       0   \n",
              "\n",
              "   mnth_8  mnth_9  mnth_10  mnth_11  mnth_12  hr_0  hr_1  hr_2  hr_3  hr_4  \\\n",
              "0       0       0        0        0        0     1     0     0     0     0   \n",
              "1       0       0        0        0        0     0     1     0     0     0   \n",
              "2       0       0        0        0        0     0     0     1     0     0   \n",
              "3       0       0        0        0        0     0     0     0     1     0   \n",
              "4       0       0        0        0        0     0     0     0     0     1   \n",
              "5       0       0        0        0        0     0     0     0     0     0   \n",
              "6       0       0        0        0        0     0     0     0     0     0   \n",
              "7       0       0        0        0        0     0     0     0     0     0   \n",
              "8       0       0        0        0        0     0     0     0     0     0   \n",
              "9       0       0        0        0        0     0     0     0     0     0   \n",
              "\n",
              "   hr_5  hr_6  hr_7  hr_8  hr_9  hr_10  hr_11  hr_12  hr_13  hr_14  hr_15  \\\n",
              "0     0     0     0     0     0      0      0      0      0      0      0   \n",
              "1     0     0     0     0     0      0      0      0      0      0      0   \n",
              "2     0     0     0     0     0      0      0      0      0      0      0   \n",
              "3     0     0     0     0     0      0      0      0      0      0      0   \n",
              "4     0     0     0     0     0      0      0      0      0      0      0   \n",
              "5     1     0     0     0     0      0      0      0      0      0      0   \n",
              "6     0     1     0     0     0      0      0      0      0      0      0   \n",
              "7     0     0     1     0     0      0      0      0      0      0      0   \n",
              "8     0     0     0     1     0      0      0      0      0      0      0   \n",
              "9     0     0     0     0     1      0      0      0      0      0      0   \n",
              "\n",
              "   hr_16  hr_17  hr_18  hr_19  hr_20  hr_21  hr_22  hr_23  weekday_0  \\\n",
              "0      0      0      0      0      0      0      0      0          0   \n",
              "1      0      0      0      0      0      0      0      0          0   \n",
              "2      0      0      0      0      0      0      0      0          0   \n",
              "3      0      0      0      0      0      0      0      0          0   \n",
              "4      0      0      0      0      0      0      0      0          0   \n",
              "5      0      0      0      0      0      0      0      0          0   \n",
              "6      0      0      0      0      0      0      0      0          0   \n",
              "7      0      0      0      0      0      0      0      0          0   \n",
              "8      0      0      0      0      0      0      0      0          0   \n",
              "9      0      0      0      0      0      0      0      0          0   \n",
              "\n",
              "   weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  weekday_6  \n",
              "0          0          0          0          0          0          1  \n",
              "1          0          0          0          0          0          1  \n",
              "2          0          0          0          0          0          1  \n",
              "3          0          0          0          0          0          1  \n",
              "4          0          0          0          0          0          1  \n",
              "5          0          0          0          0          0          1  \n",
              "6          0          0          0          0          0          1  \n",
              "7          0          0          0          0          0          1  \n",
              "8          0          0          0          0          0          1  \n",
              "9          0          0          0          0          0          1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "JrGOLuoBbhaU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Scaling target variables\n",
        "To make training the network easier, we'll standardize each of the continuous variables. That is, we'll shift and scale the variables such that they have zero mean and a standard deviation of 1.\n",
        "\n",
        "The scaling factors are saved so we can go backwards when we use the network for predictions."
      ]
    },
    {
      "metadata": {
        "id": "AVEurtojbpeD",
        "colab_type": "code",
        "outputId": "f63e89e0-cc43-4031-ba4b-bd69bd04bb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "cell_type": "code",
      "source": [
        "quant_features = ['casual', 'registered', 'cnt', 'temp', 'hum', 'windspeed']\n",
        "# Store scalings in a dictionary so we can convert back later\n",
        "scaled_features = {}\n",
        "for each in quant_features:\n",
        "    mean, std = data[each].mean(), data[each].std()\n",
        "    scaled_features[each] = [mean, std]\n",
        "    data.loc[:, each] = (data[each] - mean)/std\n",
        "\n",
        "print(scaled_features)\n",
        "data[:4]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'casual': [35.67621842453536, 49.305030387053186], 'registered': [153.78686920996606, 151.35728591258317], 'cnt': [189.46308763450142, 181.38759909186527], 'temp': [0.4969871684216586, 0.19255612124972407], 'hum': [0.6272288394038822, 0.1929298340629125], 'windspeed': [0.1900976063064631, 0.12234022857279413]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>yr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>temp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "      <th>season_1</th>\n",
              "      <th>season_2</th>\n",
              "      <th>season_3</th>\n",
              "      <th>season_4</th>\n",
              "      <th>weathersit_1</th>\n",
              "      <th>weathersit_2</th>\n",
              "      <th>weathersit_3</th>\n",
              "      <th>weathersit_4</th>\n",
              "      <th>mnth_1</th>\n",
              "      <th>mnth_2</th>\n",
              "      <th>mnth_3</th>\n",
              "      <th>mnth_4</th>\n",
              "      <th>mnth_5</th>\n",
              "      <th>mnth_6</th>\n",
              "      <th>mnth_7</th>\n",
              "      <th>mnth_8</th>\n",
              "      <th>mnth_9</th>\n",
              "      <th>mnth_10</th>\n",
              "      <th>mnth_11</th>\n",
              "      <th>mnth_12</th>\n",
              "      <th>hr_0</th>\n",
              "      <th>hr_1</th>\n",
              "      <th>hr_2</th>\n",
              "      <th>hr_3</th>\n",
              "      <th>hr_4</th>\n",
              "      <th>hr_5</th>\n",
              "      <th>hr_6</th>\n",
              "      <th>hr_7</th>\n",
              "      <th>hr_8</th>\n",
              "      <th>hr_9</th>\n",
              "      <th>hr_10</th>\n",
              "      <th>hr_11</th>\n",
              "      <th>hr_12</th>\n",
              "      <th>hr_13</th>\n",
              "      <th>hr_14</th>\n",
              "      <th>hr_15</th>\n",
              "      <th>hr_16</th>\n",
              "      <th>hr_17</th>\n",
              "      <th>hr_18</th>\n",
              "      <th>hr_19</th>\n",
              "      <th>hr_20</th>\n",
              "      <th>hr_21</th>\n",
              "      <th>hr_22</th>\n",
              "      <th>hr_23</th>\n",
              "      <th>weekday_0</th>\n",
              "      <th>weekday_1</th>\n",
              "      <th>weekday_2</th>\n",
              "      <th>weekday_3</th>\n",
              "      <th>weekday_4</th>\n",
              "      <th>weekday_5</th>\n",
              "      <th>weekday_6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.334609</td>\n",
              "      <td>0.947345</td>\n",
              "      <td>-1.553844</td>\n",
              "      <td>-0.662736</td>\n",
              "      <td>-0.930162</td>\n",
              "      <td>-0.956312</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.438475</td>\n",
              "      <td>0.895513</td>\n",
              "      <td>-1.553844</td>\n",
              "      <td>-0.561326</td>\n",
              "      <td>-0.804632</td>\n",
              "      <td>-0.823998</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.438475</td>\n",
              "      <td>0.895513</td>\n",
              "      <td>-1.553844</td>\n",
              "      <td>-0.622172</td>\n",
              "      <td>-0.837666</td>\n",
              "      <td>-0.868103</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.334609</td>\n",
              "      <td>0.636351</td>\n",
              "      <td>-1.553844</td>\n",
              "      <td>-0.662736</td>\n",
              "      <td>-0.949983</td>\n",
              "      <td>-0.972851</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   yr  holiday      temp       hum  windspeed    casual  registered       cnt  \\\n",
              "0   0        0 -1.334609  0.947345  -1.553844 -0.662736   -0.930162 -0.956312   \n",
              "1   0        0 -1.438475  0.895513  -1.553844 -0.561326   -0.804632 -0.823998   \n",
              "2   0        0 -1.438475  0.895513  -1.553844 -0.622172   -0.837666 -0.868103   \n",
              "3   0        0 -1.334609  0.636351  -1.553844 -0.662736   -0.949983 -0.972851   \n",
              "\n",
              "   season_1  season_2  season_3  season_4  weathersit_1  weathersit_2  \\\n",
              "0         1         0         0         0             1             0   \n",
              "1         1         0         0         0             1             0   \n",
              "2         1         0         0         0             1             0   \n",
              "3         1         0         0         0             1             0   \n",
              "\n",
              "   weathersit_3  weathersit_4  mnth_1  mnth_2  mnth_3  mnth_4  mnth_5  mnth_6  \\\n",
              "0             0             0       1       0       0       0       0       0   \n",
              "1             0             0       1       0       0       0       0       0   \n",
              "2             0             0       1       0       0       0       0       0   \n",
              "3             0             0       1       0       0       0       0       0   \n",
              "\n",
              "   mnth_7  mnth_8  mnth_9  mnth_10  mnth_11  mnth_12  hr_0  hr_1  hr_2  hr_3  \\\n",
              "0       0       0       0        0        0        0     1     0     0     0   \n",
              "1       0       0       0        0        0        0     0     1     0     0   \n",
              "2       0       0       0        0        0        0     0     0     1     0   \n",
              "3       0       0       0        0        0        0     0     0     0     1   \n",
              "\n",
              "   hr_4  hr_5  hr_6  hr_7  hr_8  hr_9  hr_10  hr_11  hr_12  hr_13  hr_14  \\\n",
              "0     0     0     0     0     0     0      0      0      0      0      0   \n",
              "1     0     0     0     0     0     0      0      0      0      0      0   \n",
              "2     0     0     0     0     0     0      0      0      0      0      0   \n",
              "3     0     0     0     0     0     0      0      0      0      0      0   \n",
              "\n",
              "   hr_15  hr_16  hr_17  hr_18  hr_19  hr_20  hr_21  hr_22  hr_23  weekday_0  \\\n",
              "0      0      0      0      0      0      0      0      0      0          0   \n",
              "1      0      0      0      0      0      0      0      0      0          0   \n",
              "2      0      0      0      0      0      0      0      0      0          0   \n",
              "3      0      0      0      0      0      0      0      0      0          0   \n",
              "\n",
              "   weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  weekday_6  \n",
              "0          0          0          0          0          0          1  \n",
              "1          0          0          0          0          0          1  \n",
              "2          0          0          0          0          0          1  \n",
              "3          0          0          0          0          0          1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "NpCB05fccFtu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Splitting the data into training, testing, and validation sets\n",
        "\n",
        "We'll save the data for the last approximately 21 days to use as a test set after we've trained the network. We'll use this set to make predictions and compare them with the actual number of riders."
      ]
    },
    {
      "metadata": {
        "id": "Sn1grRR3cKbI",
        "colab_type": "code",
        "outputId": "f8e0bdf6-fa26-4abd-e105-6b2c1c16e41d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Save data for approximately the last 21 days \n",
        "test_data = data[-21*24:]\n",
        "\n",
        "# Now remove the test data from the data set \n",
        "data = data[:-21*24]\n",
        "\n",
        "# Separate the data into features and targets\n",
        "target_fields = ['cnt', 'casual', 'registered']\n",
        "features, targets = data.drop(target_fields, axis=1), data[target_fields]\n",
        "test_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]\n",
        "\n",
        "###\n",
        "features_list=[]\n",
        "\n",
        "for row in features.iterrows():\n",
        "    index, data = row\n",
        "    features_list.append(data.tolist())\n",
        "\n",
        "###\n",
        "targets_list = []\n",
        "\n",
        "for row in targets.iterrows():\n",
        "    index, data = row\n",
        "    targets_list.append(data.tolist())\n",
        "    \n",
        "###\n",
        "test_features_list = []\n",
        "\n",
        "for row in test_features.iterrows():\n",
        "    index, data = row\n",
        "    test_features_list.append(data.tolist())\n",
        "\n",
        "###\n",
        "test_targets_list = []\n",
        "\n",
        "for row in test_targets.iterrows():\n",
        "    index, data = row\n",
        "    test_targets_list.append(data.tolist())\n",
        "    \n",
        "\n",
        "print(type(features))\n",
        "print(features.shape, targets.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "(16875, 56) (16875, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G22J1xPfdK2y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Making train, validation and test loaders\n",
        "\n",
        "During the procedure we have to use Pytorch loaders for training, validation and testing. We will use the [**TensorDataset**](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset) class to combine features and targets tensors. We will also use batch of 50 for training and validation and 500 for testing (almost the whole set for plotting the results later)."
      ]
    },
    {
      "metadata": {
        "id": "vUpEagv6evcP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Hold out the last 60 days or so of the remaining data as a validation set\n",
        "train_features, train_targets = features_list[:-60*24], targets_list[:-60*24]\n",
        "val_features, val_targets = features_list[-60*24:], targets_list[-60*24:]\n",
        "\n",
        "\n",
        "train_features_tensors = torch.from_numpy(np.array(train_features))\n",
        "train_targets_tensors = torch.from_numpy(np.array(train_targets))\n",
        "\n",
        "val_features_tensors = torch.from_numpy(np.array(val_features))\n",
        "val_targets_tensors = torch.from_numpy(np.array(val_targets))\n",
        "\n",
        "test_features_tensors = torch.from_numpy(np.array(test_features_list))\n",
        "test_targets_tensors = torch.from_numpy(np.array(test_targets_list))\n",
        "\n",
        "\n",
        "\n",
        "########Dataset and Loaders\n",
        "batch_sizes = 50\n",
        "batch_size_test = 500\n",
        "\n",
        "data_train = TensorDataset(train_features_tensors, train_targets_tensors)\n",
        "train_loader = torch.utils.data.DataLoader(data_train, \n",
        "                                          batch_size=batch_sizes, shuffle=True)\n",
        "\n",
        "data_val = TensorDataset(val_features_tensors, val_targets_tensors)\n",
        "val_loader = torch.utils.data.DataLoader(data_val, \n",
        "                                          batch_size=batch_sizes, shuffle=True)\n",
        "\n",
        "data_test = TensorDataset(test_features_tensors, test_targets_tensors)\n",
        "test_loader = torch.utils.data.DataLoader(data_test, \n",
        "                                          batch_size=batch_size_test, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FNGXHytEfQiu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Checking some data from the loaders\n",
        "\n",
        "We will print some data to verify how they are formulated"
      ]
    },
    {
      "metadata": {
        "id": "6WbVr15Rgrnq",
        "colab_type": "code",
        "outputId": "536ecf91-359c-4f27-cc58-61be780eb7b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "cell_type": "code",
      "source": [
        "data_iter = iter(val_loader)\n",
        "sample_x, sample_y = data_iter.next()\n",
        "\n",
        "print(sample_x.shape)\n",
        "print(sample_x)\n",
        "print()\n",
        "print(sample_y.shape)\n",
        "print(sample_y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50, 56])\n",
            "tensor([[ 1.0000,  0.0000, -0.7114,  ...,  0.0000,  0.0000,  1.0000],\n",
            "        [ 1.0000,  0.0000,  0.0156,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 1.0000,  0.0000, -0.7114,  ...,  1.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 1.0000,  0.0000, -1.2307,  ...,  0.0000,  0.0000,  1.0000],\n",
            "        [ 1.0000,  0.0000, -0.2960,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 1.0000,  0.0000, -0.8153,  ...,  0.0000,  1.0000,  0.0000]],\n",
            "       dtype=torch.float64)\n",
            "\n",
            "torch.Size([50, 3])\n",
            "tensor([[-0.9343, -0.7033, -0.8905],\n",
            "        [-0.9343, -0.7033, -0.8905],\n",
            "        [ 1.5907, -0.5005,  2.0694],\n",
            "        [-1.0280, -0.7236, -0.9962],\n",
            "        [-0.6090, -0.3585, -0.6130],\n",
            "        [ 2.1145, -0.5208,  2.7036],\n",
            "        [-0.2617, -0.5208, -0.1439],\n",
            "        [-0.6255, -0.5816, -0.5602],\n",
            "        [-0.8902, -0.6830, -0.8443],\n",
            "        [-0.3609, -0.3382, -0.3223],\n",
            "        [-0.1073, -0.4396,  0.0146],\n",
            "        [ 0.7858,  1.2235,  0.5432],\n",
            "        [-0.1294, -0.0948, -0.1241],\n",
            "        [-0.9839, -0.7033, -0.9500],\n",
            "        [ 0.2566, -0.1354,  0.3516],\n",
            "        [-0.4436,  0.6150, -0.7320],\n",
            "        [ 0.8961, -0.6019,  1.2699],\n",
            "        [ 2.1145,  3.3734,  1.4351],\n",
            "        [ 0.4440,  0.0674,  0.5101],\n",
            "        [-1.0004, -0.7236, -0.9632],\n",
            "        [ 0.1187, -0.6425,  0.3516],\n",
            "        [ 0.0195, -0.1354,  0.0675],\n",
            "        [ 0.3999,  0.5542,  0.2987],\n",
            "        [-0.8405, -0.5613, -0.8245],\n",
            "        [-1.0114, -0.7236, -0.9764],\n",
            "        [ 0.2125, -0.2165,  0.3251],\n",
            "        [-0.3995, -0.3179, -0.3752],\n",
            "        [ 0.9126, -0.0746,  1.1180],\n",
            "        [ 1.1883,  1.9739,  0.7810],\n",
            "        [ 0.2510, -0.1354,  0.3450],\n",
            "        [-0.0246, -0.6019,  0.1666],\n",
            "        [ 1.3151,  1.8117,  0.9858],\n",
            "        [-0.9343, -0.6627, -0.9037],\n",
            "        [ 0.5873,  0.7367,  0.4639],\n",
            "        [ 0.1739, -0.2571,  0.2921],\n",
            "        [ 0.0416, -0.0340,  0.0609],\n",
            "        [ 0.1849,  0.5339,  0.0477],\n",
            "        [ 0.2125, -0.5208,  0.4242],\n",
            "        [ 0.4330,  0.0877,  0.4903],\n",
            "        [-0.3168,  0.1688, -0.4346],\n",
            "        [ 2.1751, -0.5410,  2.7829],\n",
            "        [ 1.2710, -0.6019,  1.7192],\n",
            "        [-0.9894, -0.6019, -0.9896],\n",
            "        [-1.0225, -0.7033, -0.9962],\n",
            "        [ 0.4109, -0.3991,  0.6225],\n",
            "        [ 0.1794,  0.0674,  0.1930],\n",
            "        [-0.2396, -0.2571, -0.2034],\n",
            "        [-1.0114, -0.6830, -0.9896],\n",
            "        [ 0.3723,  0.1688,  0.3912],\n",
            "        [-0.1459, -0.3788, -0.0514]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9UhOF3aug6r-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### We make a simple RNN\n",
        "\n",
        "We define input size, output size, hidden dimensions and hidden layers. "
      ]
    },
    {
      "metadata": {
        "id": "F_pl5rcvheaF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.hidden_dim=hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # define an RNN with specified parameters\n",
        "        # batch_first means that the first dim of the input and output will be the batch_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
        "        \n",
        "        # last, fully-connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x (batch_size, seq_length, input_size)\n",
        "        # hidden (n_layers, batch_size, hidden_dim)\n",
        "        # r_out (batch_size, time_step, hidden_size)\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # get RNN outputs\n",
        "        r_out, hidden = self.rnn(x, hidden)\n",
        "        # shape output to be (batch_size*seq_length, hidden_dim)\n",
        "        r_out = r_out.view(-1, self.hidden_dim)  \n",
        "        \n",
        "        # get final output \n",
        "        output = self.fc(r_out)\n",
        "        \n",
        "        return output, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qLnuKvwWiPg8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## We initialize the RNN\n",
        "\n",
        "We define the parameters here. The input size is 56 as we saw the features.shape above. The output size is 3 as the targets.shape above. \n",
        "#### Choose the number of hidden nodes\n",
        "   In a model where all the weights are optimized, the more hidden nodes you have, the more accurate the predictions of the model will be. (A fully optimized model could have weights of zero, after all.) However, the more hidden nodes you have, the harder it will be to optimize the weights of the model, and the more likely it will be that suboptimal weights will lead to overfitting. With overfitting, the model will memorize the training data instead of learning the true pattern, and won't generalize well to unseen data.\n",
        "   You can look at the losses dictionary for a metric of the network performance. If the number of hidden units is too low, then the model won't have enough space to learn and if it is too high there are too many options for the direction that the learning can take. The trick here is to find the right balance in number of hidden units you choose. You'll generally find that the best number of hidden nodes to use ends up being between the number of input and output nodes."
      ]
    },
    {
      "metadata": {
        "id": "Cd1e7xlej9ev",
        "colab_type": "code",
        "outputId": "42ac34fa-5987-4aef-d362-fc90980d74b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "input_size=56 \n",
        "output_size=3\n",
        "hidden_dim=20\n",
        "n_layers=4\n",
        "\n",
        "# instantiate an RNN\n",
        "net = RNN(input_size, output_size, hidden_dim, n_layers)\n",
        "print(net)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (rnn): RNN(56, 20, num_layers=4, batch_first=True)\n",
            "  (fc): Linear(in_features=20, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4GrfEI57Abee",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Connect to google drive"
      ]
    },
    {
      "metadata": {
        "id": "GbIpaWkbAX_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Connect with drive\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QfMmIbQEkTrR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### MSELoss for criterion\n",
        "\n",
        "We choose MSELoss for finding the error between the outputs and the targets ([loss-functions](https://pytorch.org/docs/stable/nn.html#loss-functions))\n",
        "Also [Adam](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) for optimizer as it is prefered for RNNs\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "3Z4pVgP0kMQV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FsyVK6OTlPdz",
        "colab_type": "code",
        "outputId": "e37ee964-9c94-4ed4-84de-1b658ddba864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121825
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 40 # 30 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 50\n",
        "\n",
        "losses = {'train':[], 'validation':[]}\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "## Casts all floating point parameters and buffers to double datatype.\n",
        "net.double()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = None\n",
        "\n",
        "    # batch loop\n",
        "    for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "        # move model to GPU, if available\n",
        "        train_on_gpu = torch.cuda.is_available()\n",
        "        if(train_on_gpu):\n",
        "            net.cuda()\n",
        "        net.train()    \n",
        "        # make sure you iterate over completely full batches, only\n",
        "        n_batches = len(train_loader.dataset)//50\n",
        "        if(batch_i > n_batches):\n",
        "            break            \n",
        "            \n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs.unsqueeze(1), h)\n",
        "\n",
        "        h = h.data\n",
        "        # calculate the loss and perform backprop       \n",
        "        train_loss = criterion(output, labels)\n",
        "        \n",
        "        losses['train'].append(train_loss.item())\n",
        "\n",
        "        train_loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            with torch.no_grad():\n",
        "                # Get validation loss\n",
        "                h = None\n",
        "                val_losses = []\n",
        "                net.eval()\n",
        "                for inputs, labels in val_loader:\n",
        "\n",
        "                    if(train_on_gpu):\n",
        "                        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                    output, val_h = net(inputs.unsqueeze(1), h)\n",
        "                \n",
        "                    val_loss = criterion(output, labels)\n",
        "                \n",
        "                    losses['validation'].append(val_loss.item())\n",
        "\n",
        "                    val_losses.append(val_loss.item())\n",
        "                \n",
        "                    #save checkpoint\n",
        "                   # net.cpu()\n",
        "                \n",
        "                    checkpoint = {'model': net,                 \n",
        "                     'state_dict': net.state_dict(),\n",
        "                     'optimizer_state_dict': optimizer.state_dict\n",
        "                     }\n",
        "                  \n",
        "                    print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                          \"Step: {}...\".format(counter),\n",
        "                          \"Train Loss: {:.6f}...\".format(train_loss),\n",
        "                          \"Val Loss: {:.6f}\".format(val_loss))\n",
        "                    \n",
        "                    if val_loss <= valid_loss_min:\n",
        "                        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                        valid_loss_min,\n",
        "                        val_loss))\n",
        "                        torch.save(checkpoint, 'drive/My Drive/Colab Notebooks/colabArchives/model_soloupis_bikeShare_PR1.pt')\n",
        "                        valid_loss_min = val_loss\n",
        "                 \n",
        "                #net.cuda()\n",
        "                #net.train()\n",
        "           \n",
        "                    \n",
        "            "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 2.380201\n",
            "Validation loss decreased (inf --> 2.380201).  Saving model ...\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 0.904890\n",
            "Validation loss decreased (2.380201 --> 0.904890).  Saving model ...\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.080755\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.186516\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.133741\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 0.652927\n",
            "Validation loss decreased (0.904890 --> 0.652927).  Saving model ...\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.734242\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 0.943256\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.201993\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.205109\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.575300\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.013916\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 0.817099\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.129899\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.228421\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 0.927714\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.453821\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 0.834759\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.156957\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.193980\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.680013\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 0.644277\n",
            "Validation loss decreased (0.652927 --> 0.644277).  Saving model ...\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 0.857851\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.257007\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 0.945979\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 0.873709\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.019066\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.251405\n",
            "Epoch: 1/40... Step: 50... Train Loss: 0.567000... Val Loss: 1.558819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 1.201733\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 1.678914\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.681805\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.698097\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 1.334771\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.889568\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.933400\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 1.369776\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.984361\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.990866\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.941199\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.784166\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 1.117228\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.597566\n",
            "Validation loss decreased (0.644277 --> 0.597566).  Saving model ...\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.551142\n",
            "Validation loss decreased (0.597566 --> 0.551142).  Saving model ...\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.596901\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.754802\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 1.172889\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.919119\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 1.244706\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 1.022531\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 1.356388\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 1.040564\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.621458\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 1.428443\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.580434\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 1.005839\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 0.749645\n",
            "Epoch: 1/40... Step: 100... Train Loss: 0.610906... Val Loss: 1.038108\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.497181\n",
            "Validation loss decreased (0.551142 --> 0.497181).  Saving model ...\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.739353\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.571335\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.703423\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.948321\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.809122\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.808824\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.686003\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.842845\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 1.094726\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.473275\n",
            "Validation loss decreased (0.497181 --> 0.473275).  Saving model ...\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.684880\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.448101\n",
            "Validation loss decreased (0.473275 --> 0.448101).  Saving model ...\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.847961\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.756346\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.759636\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 1.106309\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.549317\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.915191\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.658587\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.655311\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.646988\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.729692\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.864469\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.407140\n",
            "Validation loss decreased (0.448101 --> 0.407140).  Saving model ...\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.736560\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.493653\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.374138\n",
            "Validation loss decreased (0.407140 --> 0.374138).  Saving model ...\n",
            "Epoch: 1/40... Step: 150... Train Loss: 0.355170... Val Loss: 0.868895\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.757706\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.526667\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.380898\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.364426\n",
            "Validation loss decreased (0.374138 --> 0.364426).  Saving model ...\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.617410\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.526035\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.590549\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.559112\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.412601\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.524961\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.566782\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.722922\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.507332\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.629514\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.571605\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.493312\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.490804\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.751420\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.459278\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 1.078194\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.696407\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.612950\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.619092\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.373726\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.470113\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.592186\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.376270\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.626429\n",
            "Epoch: 1/40... Step: 200... Train Loss: 0.535698... Val Loss: 0.671445\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.497854\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.702457\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.276371\n",
            "Validation loss decreased (0.364426 --> 0.276371).  Saving model ...\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.897635\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.516102\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.207997\n",
            "Validation loss decreased (0.276371 --> 0.207997).  Saving model ...\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.459712\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.324147\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.379275\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.611670\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.472394\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.445261\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.523254\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.280665\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.688547\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.473755\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.535905\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.368597\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.405950\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.779074\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.392185\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.686233\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.445011\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.409551\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.454184\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.538551\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.501905\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.450418\n",
            "Epoch: 1/40... Step: 250... Train Loss: 0.292074... Val Loss: 0.889531\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.458215\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.548307\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.471575\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.269297\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.666167\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.469502\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.374801\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.419720\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.402793\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.442173\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.788708\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.347012\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.431423\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.435530\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.535552\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.278513\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.409463\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.565030\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.408370\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.599540\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.387875\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.384511\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.414286\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.394390\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.453314\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.339381\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.730760\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.762182\n",
            "Epoch: 1/40... Step: 300... Train Loss: 0.397574... Val Loss: 0.606886\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.417809\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.515160\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.498253\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.507372\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.349351\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.445107\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.511226\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.725501\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.580040\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.236634\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.349359\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.436435\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.697365\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.239176\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.379563\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.548927\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.392731\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.569913\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.255797\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.367260\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.506165\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.606294\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.477749\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.283510\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.708516\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.683014\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.476841\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.368615\n",
            "Epoch: 2/40... Step: 350... Train Loss: 0.391646... Val Loss: 0.433156\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.309681\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.485605\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.610033\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.419402\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.567080\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.512582\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.445981\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.344340\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.529506\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.312378\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.347810\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.441236\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.451908\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.577578\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.555595\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.519823\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.642169\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.553749\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.364418\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.702700\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.704891\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.513172\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.597498\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.502848\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.464279\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.459380\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.453429\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.552528\n",
            "Epoch: 2/40... Step: 400... Train Loss: 0.249524... Val Loss: 0.594173\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.496804\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.347720\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.568711\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.540767\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.615235\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.450028\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.451879\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.380157\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.312259\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.523545\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.545860\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.774464\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.502889\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.397124\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.415424\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.520457\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.490007\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.435636\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.333296\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.471398\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.331163\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.362909\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.446230\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.463897\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.858338\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.562043\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.537477\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.545653\n",
            "Epoch: 2/40... Step: 450... Train Loss: 0.344035... Val Loss: 0.363511\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.391290\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.553281\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.487331\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.521655\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.528308\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.419871\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.467778\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.514086\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.610689\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.567555\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.441492\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.558516\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.502473\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.461486\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.421086\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.426801\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.491158\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.591713\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.616682\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.540493\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.584383\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.507033\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.405930\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.421948\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.504891\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.602940\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.701401\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.605310\n",
            "Epoch: 2/40... Step: 500... Train Loss: 0.233617... Val Loss: 0.529424\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.326350\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.537143\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.512507\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.383372\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.471058\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.484520\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.399454\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.416832\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.526394\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.746067\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.412234\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.337173\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.374095\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.316188\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.347512\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.403888\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.492014\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.443523\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.457423\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.391251\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.491447\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.713916\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.716097\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.678441\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.483477\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.444123\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.483055\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.552352\n",
            "Epoch: 2/40... Step: 550... Train Loss: 0.127617... Val Loss: 0.490010\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.499046\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.620790\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.742759\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.333371\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.755438\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.711614\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.475354\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.483946\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.508235\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.417655\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.486672\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.481859\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.419459\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.629925\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.555252\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.742164\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.469045\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.441988\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.405573\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.402340\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.515480\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.506715\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.327961\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.420520\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.286466\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.389853\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.320568\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.373358\n",
            "Epoch: 2/40... Step: 600... Train Loss: 0.202634... Val Loss: 0.362868\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.296318\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.448548\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.628787\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.443390\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.484764\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.510671\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.624166\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.434010\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.391457\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.546859\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.574517\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.506131\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.338238\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.468907\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.463207\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.475327\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.414127\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.467064\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.462335\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.560261\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.423718\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.500270\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.483858\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.418688\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.432799\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.473577\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.561086\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.356509\n",
            "Epoch: 3/40... Step: 650... Train Loss: 0.149774... Val Loss: 0.616155\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.485653\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.413797\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.545763\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.408727\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.728170\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.556064\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.416595\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.405467\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.453206\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.517760\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.522276\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.376701\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.474243\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.494278\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.555782\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.435261\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.430259\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.532512\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.356588\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.507519\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.509510\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.449057\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.476699\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.434001\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.528204\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.464785\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.423611\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.513534\n",
            "Epoch: 3/40... Step: 700... Train Loss: 0.168577... Val Loss: 0.566639\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.313510\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.556103\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.572529\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.506224\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.461178\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.386639\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.543646\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.454031\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.377017\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.350387\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.530939\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.584880\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.524328\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.400545\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.446446\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.381403\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.449772\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.577533\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.444984\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.539402\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.396089\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.512660\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.369825\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.479372\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.364903\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.372437\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.466675\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.543449\n",
            "Epoch: 3/40... Step: 750... Train Loss: 0.184468... Val Loss: 0.397732\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.448735\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.384602\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.474656\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.662636\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.324943\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.362445\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.440015\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.526570\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.519809\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.502443\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.540073\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.634493\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.618792\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.387435\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.479699\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.403058\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.464464\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.332113\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.453059\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.539513\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.350652\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.355116\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.334511\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.584468\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.480732\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.409123\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.327692\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.489530\n",
            "Epoch: 3/40... Step: 800... Train Loss: 0.121655... Val Loss: 0.310686\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.404884\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.463585\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.529255\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.367184\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.536323\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.315363\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.520055\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.403395\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.401906\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.422075\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.304339\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.547638\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.385237\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.732168\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.378346\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.357934\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.486632\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.305891\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.301664\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.442411\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.385086\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.427347\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.416391\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.272612\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.432275\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.586462\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.453363\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.461196\n",
            "Epoch: 3/40... Step: 850... Train Loss: 0.144882... Val Loss: 0.452611\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.475653\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.599078\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.365701\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.410584\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.273694\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.342084\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.345302\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.551841\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.364746\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.424431\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.399610\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.449546\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.371903\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.516312\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.329526\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.357169\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.397775\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.410281\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.259236\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.587843\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.556665\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.542108\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.505038\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.458622\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.332443\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.382147\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.458983\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.281118\n",
            "Epoch: 3/40... Step: 900... Train Loss: 0.195470... Val Loss: 0.547223\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.499661\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.228408\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.499602\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.439539\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.446506\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.363391\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.417274\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.599183\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.504562\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.430969\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.391878\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.613533\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.382273\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.338408\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.442931\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.318967\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.384634\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.393251\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.499328\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.443254\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.436556\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.502937\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.397134\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.428139\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.234250\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.336964\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.433806\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.624330\n",
            "Epoch: 4/40... Step: 950... Train Loss: 0.116512... Val Loss: 0.335918\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.367108\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.316886\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.464080\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.337779\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.414293\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.433152\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.406688\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.425944\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.431776\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.389900\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.298498\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.466190\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.452502\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.563947\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.413067\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.453467\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.417581\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.322661\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.475839\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.297782\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.273851\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.419615\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.381113\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.493535\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.452914\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.416594\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.519747\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.426305\n",
            "Epoch: 4/40... Step: 1000... Train Loss: 0.105965... Val Loss: 0.513560\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.413928\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.394290\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.383179\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.501657\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.440003\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.361889\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.339440\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.318596\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.398717\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.372404\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.307523\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.383113\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.421608\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.357969\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.404843\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.511563\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.323026\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.358480\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.357596\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.466449\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.354526\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.256069\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.510672\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.438775\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.573313\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.264343\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.408057\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.428238\n",
            "Epoch: 4/40... Step: 1050... Train Loss: 0.154146... Val Loss: 0.432138\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.356035\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.504874\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.537654\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.389916\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.429128\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.382922\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.543201\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.367316\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.385955\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.392843\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.416605\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.399414\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.518504\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.447502\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.352875\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.394397\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.309903\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.522553\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.450247\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.412158\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.394317\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.555058\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.445533\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.391676\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.347546\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.517793\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.370855\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.273097\n",
            "Epoch: 4/40... Step: 1100... Train Loss: 0.096556... Val Loss: 0.536147\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.551139\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.461662\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.405229\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.378416\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.435668\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.381878\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.411311\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.375825\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.425234\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.434386\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.373028\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.394576\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.377967\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.465439\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.353537\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.575207\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.351182\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.325307\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.470456\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.452798\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.312967\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.284090\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.450333\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.424023\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.304258\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.443035\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.537240\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.525750\n",
            "Epoch: 4/40... Step: 1150... Train Loss: 0.048955... Val Loss: 0.363856\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.307460\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.463986\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.312057\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.383649\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.352887\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.322964\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.444505\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.408134\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.325153\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.358576\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.358782\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.272007\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.434108\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.509373\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.447648\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.358950\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.383296\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.317506\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.504739\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.472123\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.401869\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.203991\n",
            "Validation loss decreased (0.207997 --> 0.203991).  Saving model ...\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.296471\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.332246\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.227397\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.442381\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.463055\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.302888\n",
            "Epoch: 4/40... Step: 1200... Train Loss: 0.175148... Val Loss: 0.568135\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.333093\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.431472\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.378605\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.363658\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.497708\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.411916\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.491487\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.411325\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.405605\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.340301\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.336386\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.409179\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.300040\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.425327\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.255951\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.227247\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.368409\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.358477\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.377871\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.452720\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.543909\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.419074\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.390643\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.377838\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.461642\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.383433\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.307425\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.298627\n",
            "Epoch: 5/40... Step: 1250... Train Loss: 0.069242... Val Loss: 0.181122\n",
            "Validation loss decreased (0.203991 --> 0.181122).  Saving model ...\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.315446\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.470598\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.323514\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.379495\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.417061\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.473258\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.363875\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.278856\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.416906\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.441536\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.344990\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.476516\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.317905\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.348184\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.414160\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.375639\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.381169\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.408274\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.450257\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.387474\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.429267\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.419508\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.228538\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.488076\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.490012\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.381954\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.472358\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.553051\n",
            "Epoch: 5/40... Step: 1300... Train Loss: 0.191817... Val Loss: 0.339234\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.430921\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.503519\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.347648\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.358711\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.497347\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.318430\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.487642\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.336346\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.486182\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.290147\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.516404\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.580309\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.393053\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.300686\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.623968\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.242257\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.379408\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.299812\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.379975\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.502995\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.365804\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.330107\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.459133\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.421190\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.443511\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.389757\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.514835\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.365142\n",
            "Epoch: 5/40... Step: 1350... Train Loss: 0.196714... Val Loss: 0.341999\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.381914\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.573178\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.367090\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.365906\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.286269\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.354954\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.377154\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.394392\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.366722\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.238885\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.465987\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.421895\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.396328\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.303369\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.354494\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.275987\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.419056\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.311035\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.452199\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.324812\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.456478\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.353178\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.277848\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.280090\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.549505\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.380843\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.260681\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.286298\n",
            "Epoch: 5/40... Step: 1400... Train Loss: 0.079126... Val Loss: 0.339545\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.296442\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.227652\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.436672\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.229142\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.421576\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.388238\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.504547\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.331036\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.335474\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.285813\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.400802\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.384624\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.347080\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.324225\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.327563\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.701066\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.504229\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.417871\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.358420\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.404095\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.355016\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.311172\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.254840\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.409213\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.384850\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.238037\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.435010\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.377137\n",
            "Epoch: 5/40... Step: 1450... Train Loss: 0.078073... Val Loss: 0.362531\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.345834\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.282728\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.290439\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.266077\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.456601\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.372705\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.250411\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.298234\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.246381\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.506228\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.343533\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.460599\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.488193\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.276528\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.331786\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.213586\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.330618\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.401906\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.346740\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.422632\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.263163\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.400362\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.357265\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.289296\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.196730\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.440692\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.398580\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.559225\n",
            "Epoch: 5/40... Step: 1500... Train Loss: 0.059491... Val Loss: 0.414694\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.286093\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.306295\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.319711\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.356196\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.288384\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.202583\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.215415\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.256518\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.289710\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.225522\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.588116\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.265700\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.462818\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.318425\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.544020\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.362187\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.252075\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.543458\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.338502\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.445707\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.301835\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.238093\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.222903\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.463754\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.383472\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.316281\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.239094\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.362566\n",
            "Epoch: 6/40... Step: 1550... Train Loss: 0.107133... Val Loss: 0.241977\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.243550\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.289933\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.458919\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.331044\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.461740\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.238183\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.293535\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.344472\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.406937\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.278621\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.384101\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.281842\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.288573\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.276722\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.373676\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.517847\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.334668\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.265295\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.351363\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.311262\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.340065\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.264107\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.328342\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.464132\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.315475\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.358491\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.362847\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.206331\n",
            "Epoch: 6/40... Step: 1600... Train Loss: 0.084270... Val Loss: 0.300607\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.313260\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.198688\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.506540\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.362110\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.318981\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.454552\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.331676\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.344503\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.344288\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.515866\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.591988\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.370253\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.266923\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.290927\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.353574\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.406444\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.398647\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.269410\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.333489\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.365195\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.384654\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.327007\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.358046\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.208233\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.264190\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.489295\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.385448\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.324758\n",
            "Epoch: 6/40... Step: 1650... Train Loss: 0.146490... Val Loss: 0.525553\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.318021\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.359910\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.451915\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.337604\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.317278\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.429182\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.244825\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.448689\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.209500\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.487338\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.280528\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.323722\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.326224\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.331504\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.370038\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.471835\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.200313\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.228270\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.321092\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.308641\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.374743\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.356608\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.310516\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.420378\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.304841\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.296745\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.345601\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.339298\n",
            "Epoch: 6/40... Step: 1700... Train Loss: 0.139790... Val Loss: 0.361415\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.359333\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.415364\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.367839\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.354940\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.274665\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.319879\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.536163\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.446334\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.403712\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.307898\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.286148\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.425722\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.309401\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.352439\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.478203\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.404258\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.280789\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.312050\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.283837\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.339802\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.342285\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.386022\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.341462\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.307807\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.210564\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.364463\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.372616\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.254523\n",
            "Epoch: 6/40... Step: 1750... Train Loss: 0.139215... Val Loss: 0.446956\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.339451\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.333811\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.284121\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.433474\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.386658\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.354983\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.335118\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.424559\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.476103\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.426730\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.416436\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.212426\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.276026\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.381988\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.251676\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.226010\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.290025\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.379813\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.417222\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.302102\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.331832\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.246512\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.525574\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.352469\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.313005\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.316847\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.443708\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.347799\n",
            "Epoch: 6/40... Step: 1800... Train Loss: 0.119477... Val Loss: 0.302821\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.312748\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.299837\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.375020\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.324267\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.313718\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.435811\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.440805\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.250661\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.359596\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.328856\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.220395\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.202269\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.348581\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.160026\n",
            "Validation loss decreased (0.181122 --> 0.160026).  Saving model ...\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.210188\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.346780\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.214245\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.169296\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.415127\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.382391\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.307447\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.227855\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.433887\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.345709\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.310959\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.362389\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.397561\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.382545\n",
            "Epoch: 7/40... Step: 1850... Train Loss: 0.112746... Val Loss: 0.481899\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.455755\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.401311\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.216674\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.224990\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.319472\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.225711\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.191274\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.203787\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.343464\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.327459\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.313720\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.330953\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.304679\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.474307\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.253702\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.443361\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.266376\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.239065\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.338189\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.417383\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.417645\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.214048\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.491596\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.240616\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.305399\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.453967\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.298715\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.294165\n",
            "Epoch: 7/40... Step: 1900... Train Loss: 0.064558... Val Loss: 0.280241\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.433210\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.296940\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.170695\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.280841\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.282719\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.352161\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.364890\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.365043\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.327974\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.245623\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.295214\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.333208\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.350873\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.300688\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.287809\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.141626\n",
            "Validation loss decreased (0.160026 --> 0.141626).  Saving model ...\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.235466\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.231498\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.274347\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.507015\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.358167\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.330561\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.206205\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.212985\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.573556\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.329550\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.366167\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.251774\n",
            "Epoch: 7/40... Step: 1950... Train Loss: 0.056387... Val Loss: 0.322719\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.228099\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.413508\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.363199\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.261097\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.262137\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.284052\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.457564\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.444155\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.261677\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.227707\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.425667\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.257910\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.211471\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.357217\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.407173\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.295894\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.262490\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.250189\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.256076\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.537555\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.302770\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.269635\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.343900\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.381703\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.338078\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.324701\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.201502\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.294891\n",
            "Epoch: 7/40... Step: 2000... Train Loss: 0.113844... Val Loss: 0.294967\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.306902\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.443468\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.250143\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.321235\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.388154\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.238474\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.200152\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.229610\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.229168\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.258713\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.288545\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.241547\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.425084\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.202418\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.342880\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.565564\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.301888\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.316458\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.241844\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.442405\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.340963\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.358914\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.270496\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.404317\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.321907\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.269842\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.289478\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.344044\n",
            "Epoch: 7/40... Step: 2050... Train Loss: 0.105974... Val Loss: 0.363770\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.227435\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.283359\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.273338\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.314425\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.310601\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.322465\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.291659\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.345474\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.172255\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.353390\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.478340\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.230761\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.329650\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.335017\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.226936\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.360951\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.420772\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.235817\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.360032\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.327300\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.297168\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.306668\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.276602\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.302478\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.398441\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.368112\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.317127\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.195106\n",
            "Epoch: 7/40... Step: 2100... Train Loss: 0.122305... Val Loss: 0.295482\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.345320\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.263840\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.531966\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.239841\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.276051\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.387026\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.220490\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.328567\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.267168\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.291190\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.135687\n",
            "Validation loss decreased (0.141626 --> 0.135687).  Saving model ...\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.289620\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.334818\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.229273\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.208946\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.336361\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.232050\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.264013\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.305570\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.521752\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.300004\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.425350\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.356088\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.304606\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.232527\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.345992\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.413445\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.368185\n",
            "Epoch: 7/40... Step: 2150... Train Loss: 0.074578... Val Loss: 0.271831\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.462667\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.363382\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.322085\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.184698\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.245360\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.386965\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.265044\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.329628\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.378224\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.227976\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.220934\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.244581\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.350828\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.328500\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.234061\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.301843\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.297071\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.346242\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.158321\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.285891\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.383593\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.513411\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.196319\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.276051\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.182159\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.270338\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.279346\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.180242\n",
            "Epoch: 8/40... Step: 2200... Train Loss: 0.100369... Val Loss: 0.191074\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.203135\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.304959\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.432688\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.445747\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.257763\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.287387\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.231840\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.300972\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.304357\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.299529\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.367322\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.328576\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.290142\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.297881\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.179093\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.298789\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.273843\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.334260\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.168045\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.222320\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.175350\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.187725\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.315135\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.132581\n",
            "Validation loss decreased (0.135687 --> 0.132581).  Saving model ...\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.332097\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.290165\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.281086\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.249860\n",
            "Epoch: 8/40... Step: 2250... Train Loss: 0.061729... Val Loss: 0.414142\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.329610\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.299489\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.289411\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.283151\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.261538\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.296679\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.270833\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.242939\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.344153\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.336872\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.168253\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.453542\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.366525\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.298877\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.246650\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.225571\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.273518\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.207926\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.204857\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.344097\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.303025\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.330133\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.381403\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.305789\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.324036\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.223965\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.229617\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.311511\n",
            "Epoch: 8/40... Step: 2300... Train Loss: 0.105050... Val Loss: 0.292756\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.243183\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.340354\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.272132\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.428108\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.233055\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.302060\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.309906\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.334482\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.163770\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.296652\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.223892\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.235369\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.371099\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.321152\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.243282\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.244570\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.273345\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.390647\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.239865\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.246449\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.216471\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.298937\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.231122\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.247245\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.187450\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.253164\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.245108\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.343457\n",
            "Epoch: 8/40... Step: 2350... Train Loss: 0.065669... Val Loss: 0.254699\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.307296\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.250470\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.330272\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.215089\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.277618\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.237561\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.398890\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.382042\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.411664\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.268862\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.421342\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.377811\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.297548\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.323732\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.186727\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.348052\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.235614\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.350851\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.316537\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.241487\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.323652\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.195877\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.313744\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.241088\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.331276\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.289626\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.388533\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.289968\n",
            "Epoch: 8/40... Step: 2400... Train Loss: 0.062849... Val Loss: 0.301975\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.345942\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.305601\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.286847\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.148675\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.271544\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.260158\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.372852\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.317701\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.389074\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.168481\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.509119\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.217595\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.223977\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.438327\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.357778\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.317870\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.312575\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.234330\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.290047\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.218996\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.361053\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.220645\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.237483\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.313366\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.284908\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.236824\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.337601\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.312808\n",
            "Epoch: 8/40... Step: 2450... Train Loss: 0.066735... Val Loss: 0.281117\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.330363\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.272908\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.161726\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.444156\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.187108\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.330947\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.298872\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.433732\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.241652\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.193386\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.365474\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.365161\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.366694\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.343432\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.380753\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.290572\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.297383\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.267354\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.472272\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.180522\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.323353\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.271978\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.277009\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.364090\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.194739\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.309920\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.282971\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.333490\n",
            "Epoch: 9/40... Step: 2500... Train Loss: 0.095683... Val Loss: 0.339981\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.316512\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.153733\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.328033\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.193048\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.225011\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.238597\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.284083\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.196268\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.296869\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.226777\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.337293\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.079466\n",
            "Validation loss decreased (0.132581 --> 0.079466).  Saving model ...\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.387921\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.274948\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.224322\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.304365\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.374629\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.285053\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.295229\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.263500\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.255903\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.371221\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.325608\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.273705\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.235147\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.332928\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.334986\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.306897\n",
            "Epoch: 9/40... Step: 2550... Train Loss: 0.146087... Val Loss: 0.165078\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.442991\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.212729\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.319516\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.170629\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.393448\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.282693\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.307931\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.189171\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.230798\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.281238\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.241798\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.239296\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.328852\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.275234\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.279484\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.312771\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.238620\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.294936\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.301469\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.326100\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.256240\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.361720\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.306386\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.194120\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.211183\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.241560\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.165154\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.233204\n",
            "Epoch: 9/40... Step: 2600... Train Loss: 0.075355... Val Loss: 0.122676\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.239914\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.357125\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.167006\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.243115\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.225134\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.315031\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.187888\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.296373\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.305710\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.311687\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.278706\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.228714\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.183741\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.244951\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.159836\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.300898\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.133671\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.307289\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.222369\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.169866\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.282905\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.432736\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.139825\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.137794\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.290873\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.217689\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.167425\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.265108\n",
            "Epoch: 9/40... Step: 2650... Train Loss: 0.070342... Val Loss: 0.160214\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.241655\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.202548\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.387413\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.297949\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.273731\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.279729\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.344928\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.294684\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.338119\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.229311\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.260691\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.252983\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.253743\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.355800\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.158345\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.228961\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.226139\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.333860\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.283345\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.340370\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.216765\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.242171\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.297921\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.220378\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.261171\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.266974\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.523642\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.192807\n",
            "Epoch: 9/40... Step: 2700... Train Loss: 0.039353... Val Loss: 0.128522\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.277405\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.174963\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.361347\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.222288\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.211177\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.271490\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.168449\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.155448\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.293373\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.189147\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.229518\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.288949\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.230001\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.195619\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.142056\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.247076\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.161756\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.175800\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.215259\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.418109\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.241493\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.216872\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.269168\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.337470\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.394601\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.195109\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.192003\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.378572\n",
            "Epoch: 9/40... Step: 2750... Train Loss: 0.101594... Val Loss: 0.405099\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.254471\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.282905\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.222687\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.239544\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.460730\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.297614\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.274219\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.172178\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.263371\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.132524\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.322115\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.224590\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.254566\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.277713\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.254531\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.143218\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.143318\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.190059\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.321382\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.233105\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.233636\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.213084\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.286292\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.274145\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.165081\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.173584\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.242379\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.305259\n",
            "Epoch: 10/40... Step: 2800... Train Loss: 0.134117... Val Loss: 0.125453\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.238341\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.174684\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.223814\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.205529\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.172462\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.218284\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.261138\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.347851\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.192218\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.219647\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.206188\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.297565\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.352377\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.209866\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.343019\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.223133\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.263302\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.212479\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.174210\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.174552\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.127992\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.204441\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.199799\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.184521\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.301268\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.280407\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.312381\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.183507\n",
            "Epoch: 10/40... Step: 2850... Train Loss: 0.106125... Val Loss: 0.223919\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.188518\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.233348\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.251516\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.216285\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.287425\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.271236\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.262446\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.227864\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.294250\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.195122\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.230016\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.295543\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.208642\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.135991\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.163663\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.274064\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.206920\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.295064\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.230102\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.165498\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.339297\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.134290\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.220538\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.452683\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.245221\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.292631\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.179718\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.260881\n",
            "Epoch: 10/40... Step: 2900... Train Loss: 0.052637... Val Loss: 0.284769\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.223988\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.282260\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.284513\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.175556\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.159448\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.170995\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.354929\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.199621\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.248008\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.343769\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.295575\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.152727\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.145402\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.125683\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.248596\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.212934\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.234530\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.357693\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.277614\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.191651\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.291199\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.311046\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.170982\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.191089\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.164832\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.278993\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.183350\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.137430\n",
            "Epoch: 10/40... Step: 2950... Train Loss: 0.054154... Val Loss: 0.137424\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.301778\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.167904\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.175739\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.186897\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.297019\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.145858\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.227590\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.195614\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.239917\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.252128\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.164497\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.232269\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.159541\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.260528\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.244011\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.241556\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.154258\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.108102\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.183938\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.176779\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.143878\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.201538\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.289654\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.158864\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.231101\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.481865\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.204732\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.203059\n",
            "Epoch: 10/40... Step: 3000... Train Loss: 0.113933... Val Loss: 0.247887\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.144768\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.393900\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.189199\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.248834\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.221276\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.187012\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.270114\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.307849\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.186464\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.235089\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.108296\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.215844\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.424417\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.130122\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.340932\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.152676\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.129921\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.156942\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.178687\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.239425\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.259085\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.194431\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.246349\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.113841\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.269253\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.346949\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.173388\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.126718\n",
            "Epoch: 10/40... Step: 3050... Train Loss: 0.184804... Val Loss: 0.201296\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.275810\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.250305\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.190986\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.309780\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.296937\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.237842\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.168480\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.157240\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.310945\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.114991\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.176779\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.211990\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.280342\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.329784\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.300533\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.252713\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.176254\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.224870\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.269127\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.183875\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.200248\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.221599\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.227166\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.152675\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.209657\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.180924\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.128334\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.140177\n",
            "Epoch: 11/40... Step: 3100... Train Loss: 0.104438... Val Loss: 0.144636\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.335411\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.203167\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.206568\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.204276\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.290986\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.333451\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.356853\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.145683\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.239403\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.162882\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.156721\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.208913\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.197422\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.207246\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.167136\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.198556\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.252310\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.176624\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.135054\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.264835\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.209402\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.234418\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.162227\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.202744\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.153117\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.256855\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.188979\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.192148\n",
            "Epoch: 11/40... Step: 3150... Train Loss: 0.088784... Val Loss: 0.159421\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.494057\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.305366\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.138431\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.273971\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.172477\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.243268\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.195022\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.257465\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.124817\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.278976\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.101542\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.199413\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.219773\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.239594\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.199833\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.167263\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.284991\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.393728\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.175289\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.207786\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.188631\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.209332\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.208263\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.145035\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.113222\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.141862\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.246411\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.158353\n",
            "Epoch: 11/40... Step: 3200... Train Loss: 0.064417... Val Loss: 0.287068\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.363307\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.170149\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.197796\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.272514\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.158714\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.284570\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.268781\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.263727\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.373493\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.295294\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.325420\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.162143\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.166570\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.159991\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.258940\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.209483\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.171929\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.278651\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.110112\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.217067\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.273478\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.300552\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.205713\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.192820\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.236700\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.285050\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.312350\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.154059\n",
            "Epoch: 11/40... Step: 3250... Train Loss: 0.058058... Val Loss: 0.141863\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.275475\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.271964\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.248643\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.211217\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.246017\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.215883\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.256889\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.451823\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.141890\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.154517\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.152603\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.258074\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.117095\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.195137\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.144113\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.208299\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.177362\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.189133\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.161628\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.110046\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.195451\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.255184\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.202369\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.368399\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.178275\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.180305\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.190326\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.221280\n",
            "Epoch: 11/40... Step: 3300... Train Loss: 0.074205... Val Loss: 0.186130\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.274653\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.308693\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.361034\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.115705\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.167023\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.262519\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.354017\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.328226\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.180124\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.211131\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.180487\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.263679\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.211747\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.315719\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.180583\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.187112\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.307103\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.273776\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.233178\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.362650\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.276833\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.179404\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.349055\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.238444\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.211661\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.242605\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.209720\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.185393\n",
            "Epoch: 11/40... Step: 3350... Train Loss: 0.078673... Val Loss: 0.180431\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.136262\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.361769\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.349278\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.234773\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.173844\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.246904\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.111321\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.241509\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.264878\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.229004\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.249551\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.182480\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.200997\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.326077\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.181022\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.125878\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.164634\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.227889\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.285941\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.189309\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.163982\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.142122\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.176233\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.427168\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.205825\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.151631\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.302328\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.143075\n",
            "Epoch: 12/40... Step: 3400... Train Loss: 0.038010... Val Loss: 0.207063\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.241476\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.131862\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.189534\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.219206\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.151018\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.207877\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.160266\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.206764\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.313792\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.223949\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.307774\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.227978\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.105292\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.213173\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.200090\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.162514\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.236010\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.243296\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.257174\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.132643\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.190789\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.132665\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.248288\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.240709\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.144645\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.356739\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.163466\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.238443\n",
            "Epoch: 12/40... Step: 3450... Train Loss: 0.074591... Val Loss: 0.189320\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.365292\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.138969\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.140820\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.201014\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.210996\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.161825\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.200321\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.182258\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.146772\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.174592\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.170518\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.147947\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.246248\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.246393\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.180988\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.312849\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.224433\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.227120\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.178114\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.228345\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.174694\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.198381\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.282215\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.363899\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.195857\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.215136\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.232271\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.290251\n",
            "Epoch: 12/40... Step: 3500... Train Loss: 0.073160... Val Loss: 0.205460\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.271471\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.332138\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.217880\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.175235\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.119635\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.109109\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.223895\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.152296\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.134134\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.333097\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.240659\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.376366\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.249440\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.255847\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.169757\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.148051\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.150619\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.233667\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.143338\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.170401\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.256768\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.231015\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.239783\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.256025\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.216092\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.133647\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.145973\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.130010\n",
            "Epoch: 12/40... Step: 3550... Train Loss: 0.124544... Val Loss: 0.182899\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.182901\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.260007\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.307035\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.264112\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.233170\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.099985\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.177838\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.181975\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.198941\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.206353\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.253057\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.193278\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.317392\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.211154\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.243750\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.276432\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.331728\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.151413\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.162897\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.205739\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.440104\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.177153\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.170483\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.151889\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.256856\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.206745\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.133038\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.239715\n",
            "Epoch: 12/40... Step: 3600... Train Loss: 0.061066... Val Loss: 0.274432\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.255215\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.160909\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.240140\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.259824\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.267790\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.194471\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.256230\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.347038\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.245991\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.158468\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.170671\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.203443\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.253679\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.317035\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.143457\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.144953\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.288879\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.267815\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.162545\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.172798\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.148872\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.202180\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.160771\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.225349\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.189550\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.065199\n",
            "Validation loss decreased (0.079466 --> 0.065199).  Saving model ...\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.108931\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.179284\n",
            "Epoch: 12/40... Step: 3650... Train Loss: 0.069334... Val Loss: 0.138624\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.257720\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.151004\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.150447\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.147006\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.231827\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.124644\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.126942\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.181860\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.218735\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.222090\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.226126\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.160058\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.151528\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.097856\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.219180\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.302372\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.117544\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.259267\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.154115\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.070960\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.277247\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.212217\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.154753\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.145342\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.150355\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.318608\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.172024\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.273497\n",
            "Epoch: 13/40... Step: 3700... Train Loss: 0.062177... Val Loss: 0.113354\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.147993\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.367834\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.144009\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.160752\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.321554\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.149565\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.133571\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.282584\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.185375\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.215602\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.311550\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.168146\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.245381\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.191938\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.152867\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.257467\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.236830\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.273009\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.128335\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.116756\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.245708\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.198833\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.293456\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.183960\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.126857\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.250376\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.246154\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.188006\n",
            "Epoch: 13/40... Step: 3750... Train Loss: 0.124923... Val Loss: 0.207835\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.222984\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.264893\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.249620\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.114833\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.249425\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.116235\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.256544\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.165830\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.125482\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.147449\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.356569\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.338149\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.172683\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.224606\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.192448\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.100034\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.114368\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.135674\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.154937\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.243884\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.274737\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.111531\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.267882\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.115768\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.355827\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.154250\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.135029\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.101407\n",
            "Epoch: 13/40... Step: 3800... Train Loss: 0.055073... Val Loss: 0.182453\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.115111\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.212104\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.271083\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.126739\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.268366\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.163595\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.139448\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.136845\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.137418\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.210304\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.223243\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.098434\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.166246\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.154843\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.141371\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.169344\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.283239\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.201329\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.142271\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.169085\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.276614\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.215596\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.298101\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.154455\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.173560\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.254232\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.138501\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.157603\n",
            "Epoch: 13/40... Step: 3850... Train Loss: 0.053827... Val Loss: 0.098573\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.264039\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.236235\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.197793\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.192910\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.197719\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.183648\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.096623\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.202014\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.222008\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.134818\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.170206\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.139925\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.169995\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.145911\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.314739\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.334011\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.112210\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.134994\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.201817\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.133047\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.141162\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.154622\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.099391\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.234087\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.175377\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.165237\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.304939\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.192084\n",
            "Epoch: 13/40... Step: 3900... Train Loss: 0.110350... Val Loss: 0.099394\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.152946\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.345323\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.260378\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.304863\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.184397\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.217993\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.149150\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.388699\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.181267\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.250501\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.145112\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.106668\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.161032\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.307697\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.195862\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.178373\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.148971\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.113300\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.130223\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.228447\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.283448\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.210945\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.130750\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.199872\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.147473\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.227632\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.170866\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.171261\n",
            "Epoch: 13/40... Step: 3950... Train Loss: 0.085817... Val Loss: 0.105900\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.274851\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.156826\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.164411\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.239822\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.510008\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.163797\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.210303\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.150786\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.259365\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.150967\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.157890\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.212363\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.234536\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.340302\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.142198\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.173757\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.197695\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.067645\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.298172\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.237640\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.189757\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.245242\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.238790\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.154017\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.194512\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.138687\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.194493\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.135548\n",
            "Epoch: 13/40... Step: 4000... Train Loss: 0.129777... Val Loss: 0.151161\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.269267\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.310941\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.299017\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.203497\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.279451\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.185700\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.199031\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.207895\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.139337\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.154647\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.119212\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.215803\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.166785\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.221873\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.121460\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.132494\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.278909\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.175376\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.342107\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.164477\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.184356\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.268969\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.228341\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.167560\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.300094\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.139188\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.193624\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.291903\n",
            "Epoch: 14/40... Step: 4050... Train Loss: 0.047688... Val Loss: 0.295199\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.240923\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.189497\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.141536\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.291127\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.180625\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.142364\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.303150\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.158025\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.301901\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.289739\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.262864\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.088578\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.160103\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.103828\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.085646\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.157219\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.185378\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.222547\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.405435\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.206348\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.267292\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.213021\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.088764\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.152773\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.147043\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.126982\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.231359\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.119232\n",
            "Epoch: 14/40... Step: 4100... Train Loss: 0.055161... Val Loss: 0.171146\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.208182\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.128760\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.271957\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.157945\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.120009\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.127706\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.111368\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.250023\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.289938\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.259561\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.201354\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.098129\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.215257\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.323771\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.389432\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.132128\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.245157\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.175272\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.187457\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.290082\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.248115\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.181254\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.191521\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.182929\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.154363\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.243941\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.249895\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.238368\n",
            "Epoch: 14/40... Step: 4150... Train Loss: 0.080015... Val Loss: 0.153099\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.157872\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.113628\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.223339\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.163356\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.174486\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.196629\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.390842\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.244526\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.136522\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.199031\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.213032\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.109609\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.155924\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.194617\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.257805\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.126735\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.234344\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.188656\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.196119\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.114009\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.134986\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.213725\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.126892\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.227284\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.243874\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.242387\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.180079\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.272993\n",
            "Epoch: 14/40... Step: 4200... Train Loss: 0.104885... Val Loss: 0.327533\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.192629\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.239652\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.103419\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.200447\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.186698\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.154317\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.207081\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.128482\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.262076\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.105526\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.342931\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.113358\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.142398\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.130681\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.120653\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.191899\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.169095\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.215248\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.141611\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.085301\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.171697\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.107574\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.174012\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.176961\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.245097\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.194229\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.377889\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.145585\n",
            "Epoch: 14/40... Step: 4250... Train Loss: 0.053580... Val Loss: 0.120442\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.146656\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.224379\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.172531\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.224466\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.177239\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.123910\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.178987\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.310395\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.166103\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.204888\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.125097\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.178729\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.169997\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.122555\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.183489\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.452121\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.143673\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.145234\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.208978\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.192582\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.133462\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.146346\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.137635\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.202223\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.185166\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.231410\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.325755\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.198582\n",
            "Epoch: 14/40... Step: 4300... Train Loss: 0.028810... Val Loss: 0.369389\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.349857\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.190381\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.102047\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.261455\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.148998\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.121547\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.198497\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.259472\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.152176\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.211476\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.094818\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.163673\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.224175\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.253784\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.127252\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.273120\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.317776\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.224686\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.227386\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.139406\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.211499\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.240444\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.161636\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.100001\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.123658\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.135562\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.107890\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.182536\n",
            "Epoch: 15/40... Step: 4350... Train Loss: 0.039884... Val Loss: 0.214072\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.272674\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.210899\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.160472\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.116437\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.224893\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.252600\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.130409\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.195092\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.115244\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.183852\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.156982\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.262862\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.195889\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.202044\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.279287\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.287542\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.168282\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.131515\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.196761\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.250172\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.184220\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.205407\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.129677\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.213762\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.114450\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.095047\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.141973\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.165473\n",
            "Epoch: 15/40... Step: 4400... Train Loss: 0.065822... Val Loss: 0.159556\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.147695\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.149260\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.132318\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.177633\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.316716\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.193974\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.258948\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.211900\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.139518\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.168916\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.094068\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.159798\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.225918\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.188992\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.178657\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.181289\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.360518\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.128703\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.190802\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.187364\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.126169\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.207709\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.164025\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.162364\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.089701\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.214522\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.196829\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.104760\n",
            "Epoch: 15/40... Step: 4450... Train Loss: 0.123379... Val Loss: 0.211972\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.357161\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.216450\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.197948\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.221998\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.148850\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.278831\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.173158\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.196678\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.110304\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.306396\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.138246\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.342868\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.111284\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.177443\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.140115\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.169645\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.091836\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.134548\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.216195\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.096144\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.151170\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.145409\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.262265\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.155915\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.175108\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.107708\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.174805\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.080555\n",
            "Epoch: 15/40... Step: 4500... Train Loss: 0.164088... Val Loss: 0.194122\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.164869\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.105194\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.142072\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.219701\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.265893\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.158861\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.164701\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.152735\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.281453\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.122923\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.099089\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.381350\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.131812\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.238651\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.133792\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.142941\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.271487\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.231618\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.106724\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.174279\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.252414\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.140293\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.129319\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.230696\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.102606\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.100879\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.137993\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.163653\n",
            "Epoch: 15/40... Step: 4550... Train Loss: 0.066775... Val Loss: 0.177904\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.235113\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.113616\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.227375\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.082392\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.154943\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.141825\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.254740\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.149073\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.191155\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.174617\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.108164\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.115270\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.152597\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.318479\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.198460\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.111691\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.183506\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.294046\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.272836\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.203426\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.238940\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.110240\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.189602\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.208049\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.146176\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.146521\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.383764\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.209475\n",
            "Epoch: 15/40... Step: 4600... Train Loss: 0.064640... Val Loss: 0.269705\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.102553\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.117216\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.320104\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.248396\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.193037\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.073731\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.163011\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.131346\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.249523\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.079121\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.238984\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.133486\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.194416\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.098490\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.131556\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.227466\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.145096\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.175181\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.096529\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.150873\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.226615\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.182226\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.201894\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.123756\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.173336\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.154436\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.131094\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.268147\n",
            "Epoch: 16/40... Step: 4650... Train Loss: 0.074510... Val Loss: 0.242451\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.183864\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.485859\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.206458\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.244831\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.181641\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.235277\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.150106\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.095541\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.251552\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.148415\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.323249\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.276853\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.116905\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.171226\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.190415\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.288991\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.121687\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.242946\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.119623\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.170364\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.135167\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.271708\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.146309\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.181127\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.121873\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.137694\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.194869\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.105544\n",
            "Epoch: 16/40... Step: 4700... Train Loss: 0.081270... Val Loss: 0.153604\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.124820\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.124439\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.101892\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.241694\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.196995\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.124637\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.167191\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.063918\n",
            "Validation loss decreased (0.065199 --> 0.063918).  Saving model ...\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.211658\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.242488\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.185493\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.143817\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.179841\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.151503\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.131431\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.149580\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.156768\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.201097\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.404182\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.142967\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.205979\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.154628\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.427310\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.206790\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.182407\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.126075\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.177338\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.279112\n",
            "Epoch: 16/40... Step: 4750... Train Loss: 0.041708... Val Loss: 0.075010\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.161718\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.335296\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.229717\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.120829\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.176846\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.131376\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.159642\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.298413\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.161932\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.121529\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.115802\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.112115\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.248379\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.099303\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.106427\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.128555\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.257570\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.125535\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.099544\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.167087\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.210311\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.252867\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.198551\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.132567\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.082724\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.170205\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.407457\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.253106\n",
            "Epoch: 16/40... Step: 4800... Train Loss: 0.067353... Val Loss: 0.087253\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.189025\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.228152\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.216253\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.172087\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.165882\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.195753\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.283649\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.364486\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.179000\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.359745\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.129408\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.149857\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.170011\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.261219\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.342229\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.186017\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.215917\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.122045\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.228238\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.181919\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.359408\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.270684\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.152111\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.158243\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.273264\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.102801\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.153507\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.199959\n",
            "Epoch: 16/40... Step: 4850... Train Loss: 0.023035... Val Loss: 0.097548\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.096393\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.257171\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.124550\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.133109\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.221812\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.167668\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.141104\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.179643\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.328342\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.175918\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.310368\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.145901\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.191531\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.193955\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.091104\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.144924\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.109210\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.157488\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.124329\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.129317\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.138031\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.180748\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.192800\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.111572\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.201512\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.137176\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.270468\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.223193\n",
            "Epoch: 16/40... Step: 4900... Train Loss: 0.093517... Val Loss: 0.416962\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.169947\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.165862\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.147041\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.239734\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.080761\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.204116\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.183465\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.109075\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.193629\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.119589\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.121536\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.203104\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.141229\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.131382\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.165536\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.174971\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.368637\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.155186\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.098895\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.328920\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.180036\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.245569\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.182133\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.202506\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.252852\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.217830\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.131601\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.120108\n",
            "Epoch: 17/40... Step: 4950... Train Loss: 0.095851... Val Loss: 0.074000\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.122862\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.179917\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.211946\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.125701\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.158540\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.156998\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.185396\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.099864\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.140293\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.163945\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.221999\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.194150\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.317049\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.180997\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.213689\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.143795\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.169710\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.098230\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.088698\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.236800\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.207209\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.257126\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.132398\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.157826\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.143192\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.127087\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.167834\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.088757\n",
            "Epoch: 17/40... Step: 5000... Train Loss: 0.045928... Val Loss: 0.135386\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.176984\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.197172\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.084193\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.262583\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.217907\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.305904\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.188341\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.143189\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.165001\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.188483\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.325722\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.171679\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.161896\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.188461\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.411175\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.133348\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.060857\n",
            "Validation loss decreased (0.063918 --> 0.060857).  Saving model ...\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.087776\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.156498\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.135786\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.281287\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.084817\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.343861\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.269540\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.072694\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.116458\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.174930\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.164568\n",
            "Epoch: 17/40... Step: 5050... Train Loss: 0.059344... Val Loss: 0.087478\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.140903\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.349028\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.135280\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.118623\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.167775\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.109551\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.371818\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.145723\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.122060\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.187678\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.222667\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.330785\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.107440\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.135559\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.304782\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.108431\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.147245\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.083306\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.257730\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.212152\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.161353\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.121585\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.111259\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.116510\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.158466\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.153420\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.222617\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.126328\n",
            "Epoch: 17/40... Step: 5100... Train Loss: 0.071951... Val Loss: 0.211542\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.152935\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.101205\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.232880\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.174692\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.237429\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.083170\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.135362\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.188402\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.296088\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.347918\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.115935\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.147471\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.161446\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.158526\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.234471\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.120633\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.147255\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.167035\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.172905\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.233067\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.155689\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.251059\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.154385\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.331654\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.115564\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.211395\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.166395\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.130429\n",
            "Epoch: 17/40... Step: 5150... Train Loss: 0.063215... Val Loss: 0.135888\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.263452\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.171140\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.361027\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.182801\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.112539\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.162571\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.118885\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.084163\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.065548\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.225489\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.130940\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.202355\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.193403\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.202218\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.137453\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.114846\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.141894\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.150738\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.297461\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.155201\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.193105\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.234314\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.166457\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.298260\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.123160\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.228319\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.323459\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.121364\n",
            "Epoch: 17/40... Step: 5200... Train Loss: 0.107847... Val Loss: 0.121319\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.122543\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.127217\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.178027\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.139452\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.131584\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.287052\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.260099\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.192169\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.133762\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.144727\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.139524\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.256400\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.118455\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.272590\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.229797\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.198249\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.149427\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.162031\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.199877\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.339192\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.389935\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.178459\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.198715\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.149389\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.202378\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.318021\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.281152\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.152358\n",
            "Epoch: 18/40... Step: 5250... Train Loss: 0.067462... Val Loss: 0.149854\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.176959\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.111362\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.243549\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.180891\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.093568\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.230074\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.093806\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.137829\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.173242\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.089652\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.110031\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.279442\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.170991\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.124284\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.123853\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.198685\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.117944\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.304848\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.316542\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.260846\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.329891\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.229274\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.249451\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.146215\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.217894\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.147540\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.126879\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.161118\n",
            "Epoch: 18/40... Step: 5300... Train Loss: 0.068706... Val Loss: 0.338302\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.165774\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.379680\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.170455\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.287128\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.191081\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.125111\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.104511\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.193562\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.153197\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.202281\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.115613\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.124694\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.133750\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.264693\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.163515\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.316236\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.212508\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.281095\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.236204\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.169116\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.082386\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.230356\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.157339\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.176710\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.260924\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.195192\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.268999\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.223499\n",
            "Epoch: 18/40... Step: 5350... Train Loss: 0.066859... Val Loss: 0.093787\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.139931\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.134611\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.120954\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.136261\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.201597\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.086091\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.158311\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.245650\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.195823\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.232354\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.253078\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.129234\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.206306\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.137064\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.291312\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.243038\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.229410\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.152980\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.294419\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.104559\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.101905\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.112048\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.360763\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.105632\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.185889\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.239131\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.138855\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.136899\n",
            "Epoch: 18/40... Step: 5400... Train Loss: 0.056540... Val Loss: 0.113525\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.104763\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.218431\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.104669\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.163320\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.249448\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.244882\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.140511\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.260478\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.138501\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.163332\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.166922\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.226092\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.128829\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.201464\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.095758\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.101258\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.157446\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.145302\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.138145\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.227059\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.340577\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.155538\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.246788\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.205368\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.108429\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.101493\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.211936\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.253297\n",
            "Epoch: 18/40... Step: 5450... Train Loss: 0.062953... Val Loss: 0.245217\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.082414\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.318027\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.095108\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.291447\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.129815\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.122937\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.169615\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.122649\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.186105\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.194908\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.172786\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.259528\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.089266\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.172507\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.120177\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.128040\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.179688\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.124901\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.165181\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.309851\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.141689\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.113185\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.192312\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.146734\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.168111\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.191619\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.254045\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.099602\n",
            "Epoch: 18/40... Step: 5500... Train Loss: 0.080616... Val Loss: 0.197134\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.216751\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.236208\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.128873\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.291206\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.176159\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.089279\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.152719\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.242691\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.118495\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.090284\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.138265\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.149717\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.345157\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.176144\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.133729\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.179055\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.096467\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.276870\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.082678\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.122201\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.120618\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.314171\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.171359\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.110721\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.285168\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.218822\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.079680\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.116866\n",
            "Epoch: 19/40... Step: 5550... Train Loss: 0.095791... Val Loss: 0.160552\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.248183\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.114153\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.143468\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.173863\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.156904\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.117424\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.204686\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.242573\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.106590\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.176495\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.121614\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.236573\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.090853\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.189797\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.154393\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.169793\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.352249\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.171673\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.184127\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.054966\n",
            "Validation loss decreased (0.060857 --> 0.054966).  Saving model ...\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.266007\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.106055\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.158524\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.124066\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.357954\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.095017\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.289797\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.257800\n",
            "Epoch: 19/40... Step: 5600... Train Loss: 0.059752... Val Loss: 0.082647\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.238509\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.179551\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.158846\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.168189\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.132236\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.102384\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.325323\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.080415\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.148969\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.216473\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.189733\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.106816\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.300341\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.130099\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.146654\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.152808\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.181087\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.141523\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.164807\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.188509\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.224057\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.172537\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.099509\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.243109\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.136014\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.263190\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.122256\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.139746\n",
            "Epoch: 19/40... Step: 5650... Train Loss: 0.128657... Val Loss: 0.267023\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.196983\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.356907\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.149972\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.220836\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.204594\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.349721\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.146905\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.155522\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.266018\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.173092\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.143113\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.170131\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.201761\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.123707\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.121895\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.121739\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.147313\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.141261\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.131220\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.312322\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.135869\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.128064\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.101112\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.127241\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.196708\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.152662\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.137733\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.139585\n",
            "Epoch: 19/40... Step: 5700... Train Loss: 0.034995... Val Loss: 0.122915\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.120208\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.204438\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.124646\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.127915\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.232876\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.181815\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.195888\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.109889\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.123334\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.257521\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.109222\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.169195\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.284287\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.221692\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.228165\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.281610\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.092928\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.087261\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.175886\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.096250\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.104996\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.282710\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.108793\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.115446\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.377333\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.107920\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.188759\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.196268\n",
            "Epoch: 19/40... Step: 5750... Train Loss: 0.094697... Val Loss: 0.201302\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.361724\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.310760\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.117430\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.078175\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.122046\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.063367\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.092844\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.211332\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.162107\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.181278\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.122707\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.189636\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.116163\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.165679\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.199112\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.137720\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.227837\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.263586\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.132689\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.228048\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.143350\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.155820\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.096480\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.137194\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.221136\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.149110\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.072417\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.225954\n",
            "Epoch: 19/40... Step: 5800... Train Loss: 0.035456... Val Loss: 0.221949\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.124392\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.292570\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.177051\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.256480\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.112827\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.154477\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.182997\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.085408\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.144910\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.229665\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.088382\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.170859\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.115251\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.190923\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.185985\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.163589\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.251040\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.232339\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.187827\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.119974\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.104381\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.152555\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.194955\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.080398\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.273276\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.106930\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.222579\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.257306\n",
            "Epoch: 19/40... Step: 5850... Train Loss: 0.034012... Val Loss: 0.202106\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.149930\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.160217\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.122166\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.218550\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.132301\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.187195\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.134643\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.123727\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.198484\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.256134\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.185274\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.207177\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.330180\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.068303\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.259254\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.081557\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.233382\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.170650\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.174617\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.202445\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.205145\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.206589\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.092332\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.137687\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.148502\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.175980\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.303765\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.169795\n",
            "Epoch: 20/40... Step: 5900... Train Loss: 0.119303... Val Loss: 0.153193\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.201315\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.140836\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.150544\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.281568\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.126537\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.117084\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.214517\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.248084\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.192608\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.203664\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.210485\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.231768\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.422571\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.123883\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.266641\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.193629\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.153127\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.187523\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.117698\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.127176\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.187454\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.201667\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.368099\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.103207\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.130420\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.251656\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.093702\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.166685\n",
            "Epoch: 20/40... Step: 5950... Train Loss: 0.064117... Val Loss: 0.103455\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.079898\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.130527\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.129425\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.127572\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.271167\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.266103\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.216528\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.139746\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.191663\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.292200\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.225316\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.267447\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.319782\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.253629\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.148863\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.145551\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.301849\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.221758\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.129817\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.197060\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.120087\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.148249\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.313375\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.107082\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.180286\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.244432\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.145814\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.101748\n",
            "Epoch: 20/40... Step: 6000... Train Loss: 0.086308... Val Loss: 0.350708\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.216697\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.146235\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.160745\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.284857\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.127699\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.294216\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.108247\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.165574\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.079996\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.146787\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.232815\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.155150\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.203603\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.228013\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.154828\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.348590\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.078901\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.163488\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.206369\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.118232\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.149004\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.102966\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.157581\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.170453\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.288857\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.191500\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.228392\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.117812\n",
            "Epoch: 20/40... Step: 6050... Train Loss: 0.097356... Val Loss: 0.336405\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.106258\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.206083\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.143824\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.180516\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.233493\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.149148\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.351208\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.144716\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.142404\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.141302\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.252994\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.129571\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.230670\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.164962\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.154848\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.126394\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.163909\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.168498\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.077770\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.110733\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.128904\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.251257\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.111045\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.116859\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.161870\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.126235\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.143153\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.199899\n",
            "Epoch: 20/40... Step: 6100... Train Loss: 0.060036... Val Loss: 0.261327\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.106714\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.314124\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.278583\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.196929\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.142046\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.140172\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.145370\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.159729\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.286334\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.093235\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.110663\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.319904\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.209323\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.315159\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.149185\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.233524\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.131752\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.171795\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.104446\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.218802\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.106756\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.198699\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.072120\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.164722\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.081093\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.125199\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.175893\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.113105\n",
            "Epoch: 20/40... Step: 6150... Train Loss: 0.060413... Val Loss: 0.110981\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.133712\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.154181\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.173197\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.102102\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.176891\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.143604\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.326635\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.111961\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.116455\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.208498\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.360696\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.161052\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.139894\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.205311\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.088398\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.175791\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.094870\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.134724\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.166537\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.172218\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.501581\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.297416\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.254565\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.226606\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.252707\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.150683\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.164380\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.166796\n",
            "Epoch: 21/40... Step: 6200... Train Loss: 0.097628... Val Loss: 0.178450\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.275370\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.257306\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.251499\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.366933\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.212912\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.088215\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.156266\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.215328\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.157259\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.148210\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.090263\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.179411\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.098267\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.147432\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.141115\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.275990\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.079827\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.179271\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.094414\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.072444\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.120806\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.156007\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.124904\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.115253\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.164840\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.089494\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.173487\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.201868\n",
            "Epoch: 21/40... Step: 6250... Train Loss: 0.070781... Val Loss: 0.153264\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.147257\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.142994\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.248299\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.163445\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.160703\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.117025\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.153517\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.154148\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.073653\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.205953\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.299588\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.112703\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.154393\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.307924\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.257307\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.216760\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.147654\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.169588\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.214976\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.140061\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.173673\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.204646\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.104419\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.104839\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.146977\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.142298\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.110129\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.209893\n",
            "Epoch: 21/40... Step: 6300... Train Loss: 0.099190... Val Loss: 0.140364\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.187393\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.184794\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.260123\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.112325\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.077621\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.243354\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.182409\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.229712\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.071005\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.109063\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.287769\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.112336\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.096043\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.108733\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.230123\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.093338\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.206123\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.254273\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.089948\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.126768\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.135864\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.169819\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.225422\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.226445\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.157863\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.214253\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.184192\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.152163\n",
            "Epoch: 21/40... Step: 6350... Train Loss: 0.217210... Val Loss: 0.224036\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.078372\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.101301\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.162971\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.185442\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.162057\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.107342\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.133390\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.199973\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.120830\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.136422\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.160350\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.278526\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.132232\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.215971\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.157433\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.078332\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.154242\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.115184\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.213528\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.168114\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.120380\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.227905\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.286695\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.414968\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.221412\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.197974\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.187377\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.182114\n",
            "Epoch: 21/40... Step: 6400... Train Loss: 0.052326... Val Loss: 0.219813\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.180049\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.124972\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.076873\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.101403\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.251344\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.154812\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.140090\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.122485\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.132710\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.136018\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.312323\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.211950\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.111977\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.166003\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.520196\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.107262\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.163858\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.294944\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.231508\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.167926\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.341474\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.236406\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.139673\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.229519\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.092353\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.158837\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.109214\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.113050\n",
            "Epoch: 21/40... Step: 6450... Train Loss: 0.071380... Val Loss: 0.101136\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.189870\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.094071\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.141995\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.317139\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.145295\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.119384\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.103797\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.120060\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.177024\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.125443\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.083412\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.308520\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.236721\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.260136\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.107324\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.227398\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.151013\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.095603\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.154491\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.154470\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.158642\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.204396\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.102508\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.341860\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.130119\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.154849\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.227633\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.099488\n",
            "Epoch: 22/40... Step: 6500... Train Loss: 0.088890... Val Loss: 0.192355\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.077342\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.237295\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.142075\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.202924\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.182527\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.180329\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.177583\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.143898\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.129227\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.081313\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.126070\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.311154\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.093760\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.142163\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.147712\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.151314\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.293893\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.111698\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.121725\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.147663\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.203458\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.181777\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.132478\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.235907\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.250683\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.228547\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.087889\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.167747\n",
            "Epoch: 22/40... Step: 6550... Train Loss: 0.059903... Val Loss: 0.093035\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.179198\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.092047\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.201758\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.125540\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.208914\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.174463\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.188164\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.153316\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.127326\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.086252\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.127509\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.068073\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.194525\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.130240\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.208904\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.225072\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.127788\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.174782\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.104723\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.250893\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.161490\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.126988\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.361333\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.235630\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.222004\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.132429\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.098033\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.191819\n",
            "Epoch: 22/40... Step: 6600... Train Loss: 0.131355... Val Loss: 0.155610\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.148159\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.139310\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.209002\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.153939\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.209704\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.097713\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.233441\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.237677\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.143975\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.129364\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.150247\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.202654\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.098125\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.119673\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.136654\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.116684\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.244325\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.136282\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.145438\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.330909\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.199834\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.201269\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.129303\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.182927\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.165845\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.117761\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.102884\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.199526\n",
            "Epoch: 22/40... Step: 6650... Train Loss: 0.064468... Val Loss: 0.090521\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.221642\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.078117\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.167548\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.251927\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.125206\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.209150\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.172519\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.189134\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.222594\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.324153\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.416919\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.170429\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.136768\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.249181\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.138901\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.158600\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.146799\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.122632\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.134191\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.120315\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.149046\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.136049\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.116067\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.200990\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.110205\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.208571\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.199932\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.214918\n",
            "Epoch: 22/40... Step: 6700... Train Loss: 0.064329... Val Loss: 0.172800\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.091961\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.093270\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.186461\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.155488\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.178170\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.127880\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.122379\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.316494\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.337684\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.155476\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.241503\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.244535\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.098803\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.219438\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.150982\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.231344\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.137511\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.078841\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.169642\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.139915\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.078526\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.280541\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.167892\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.181109\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.104538\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.225574\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.221357\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.082469\n",
            "Epoch: 22/40... Step: 6750... Train Loss: 0.066799... Val Loss: 0.112461\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.122773\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.135540\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.135984\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.099982\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.181827\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.118476\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.178316\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.152071\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.209963\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.309057\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.100323\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.136233\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.215547\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.088010\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.214101\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.217977\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.148239\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.065135\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.197115\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.109870\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.398860\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.107305\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.244670\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.341312\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.254904\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.051468\n",
            "Validation loss decreased (0.054966 --> 0.051468).  Saving model ...\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.089601\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.206916\n",
            "Epoch: 23/40... Step: 6800... Train Loss: 0.066612... Val Loss: 0.236228\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.173764\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.098091\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.161035\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.231195\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.177502\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.145471\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.125206\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.404741\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.091928\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.092263\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.147296\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.178553\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.184365\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.507821\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.163651\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.125273\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.214194\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.123092\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.073900\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.202805\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.234239\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.095029\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.245901\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.169459\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.121926\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.120221\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.098724\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.056469\n",
            "Epoch: 23/40... Step: 6850... Train Loss: 0.101373... Val Loss: 0.125421\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.220525\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.392742\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.133156\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.215773\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.125125\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.158982\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.124437\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.175218\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.133693\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.270475\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.120133\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.078642\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.141160\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.145495\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.166202\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.321701\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.260687\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.135662\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.226811\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.157168\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.165979\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.114801\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.203623\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.064943\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.272548\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.129434\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.120004\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.105680\n",
            "Epoch: 23/40... Step: 6900... Train Loss: 0.063038... Val Loss: 0.121511\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.197232\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.062046\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.149898\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.156604\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.147304\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.073395\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.220552\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.119138\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.157998\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.360166\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.307378\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.101322\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.311357\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.240746\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.188682\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.097469\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.137329\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.110665\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.259619\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.141837\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.078136\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.142854\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.203763\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.091765\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.111454\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.195518\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.142474\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.243009\n",
            "Epoch: 23/40... Step: 6950... Train Loss: 0.067388... Val Loss: 0.117715\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.169577\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.084649\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.236602\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.090593\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.195366\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.096053\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.309184\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.178419\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.203187\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.207887\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.187501\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.122755\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.093089\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.109032\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.219073\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.094874\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.146078\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.231513\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.114905\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.115400\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.345276\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.212639\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.140084\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.167503\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.223618\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.143864\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.158895\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.291832\n",
            "Epoch: 23/40... Step: 7000... Train Loss: 0.051853... Val Loss: 0.049406\n",
            "Validation loss decreased (0.051468 --> 0.049406).  Saving model ...\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.219204\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.218504\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.250657\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.177357\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.174946\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.222642\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.130452\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.243771\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.161848\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.131232\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.149874\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.139828\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.190484\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.120261\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.156219\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.187968\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.180221\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.128972\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.116696\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.124846\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.117535\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.320343\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.125485\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.172482\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.237942\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.291679\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.092013\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.167295\n",
            "Epoch: 23/40... Step: 7050... Train Loss: 0.043186... Val Loss: 0.106302\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.200892\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.154725\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.189563\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.181146\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.317341\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.146407\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.120128\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.162921\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.105693\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.171141\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.117491\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.142868\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.077100\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.112218\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.167081\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.216966\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.100960\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.282874\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.214280\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.133832\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.183752\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.247320\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.190898\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.190981\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.140993\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.175991\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.254135\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.164238\n",
            "Epoch: 24/40... Step: 7100... Train Loss: 0.088949... Val Loss: 0.373308\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.113165\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.180294\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.157754\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.231298\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.200158\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.242794\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.148036\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.209076\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.155806\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.163036\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.133140\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.181068\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.122768\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.251949\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.143165\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.175739\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.174398\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.136716\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.126534\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.147360\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.120899\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.145314\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.257151\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.211859\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.266536\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.143784\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.283216\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.134464\n",
            "Epoch: 24/40... Step: 7150... Train Loss: 0.091763... Val Loss: 0.131005\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.144932\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.257967\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.183587\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.130745\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.287739\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.153278\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.105481\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.089250\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.160757\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.150815\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.173814\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.078114\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.227310\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.103592\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.106604\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.088807\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.120139\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.133238\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.114233\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.125628\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.388422\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.297834\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.377446\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.170105\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.138376\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.174827\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.235948\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.095804\n",
            "Epoch: 24/40... Step: 7200... Train Loss: 0.060503... Val Loss: 0.222704\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.086432\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.212422\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.171609\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.368147\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.145568\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.250652\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.188263\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.292396\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.245676\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.200623\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.235470\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.123084\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.153602\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.106150\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.148045\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.160260\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.225329\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.126963\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.237789\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.214142\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.365802\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.188716\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.207103\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.264146\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.092331\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.072101\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.105338\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.239658\n",
            "Epoch: 24/40... Step: 7250... Train Loss: 0.052719... Val Loss: 0.144430\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.167502\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.207715\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.085383\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.203227\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.252047\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.141419\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.163454\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.171546\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.224529\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.175960\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.190257\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.200432\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.134182\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.178950\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.192687\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.099493\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.166466\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.099600\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.108557\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.060244\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.106068\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.145291\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.311560\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.139258\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.136482\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.145793\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.310767\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.137887\n",
            "Epoch: 24/40... Step: 7300... Train Loss: 0.035539... Val Loss: 0.121312\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.117837\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.181807\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.250098\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.125406\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.174010\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.183595\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.184314\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.306479\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.285472\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.114588\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.165006\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.115932\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.215585\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.322721\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.096068\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.326548\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.261697\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.112502\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.104961\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.182046\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.201246\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.187915\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.238191\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.150990\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.101227\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.133943\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.101452\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.091887\n",
            "Epoch: 24/40... Step: 7350... Train Loss: 0.052498... Val Loss: 0.129767\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.112111\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.143018\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.207387\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.257865\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.228490\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.165157\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.085301\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.299851\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.104368\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.079405\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.105202\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.107916\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.348444\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.079040\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.130772\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.138493\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.126479\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.097106\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.088088\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.239522\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.181600\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.131699\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.134521\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.122736\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.125639\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.083906\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.251021\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.252567\n",
            "Epoch: 25/40... Step: 7400... Train Loss: 0.034961... Val Loss: 0.280052\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.104673\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.113704\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.157864\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.160634\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.076806\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.143743\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.174275\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.150223\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.243131\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.098053\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.151885\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.175365\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.192436\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.165039\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.194232\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.262438\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.092188\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.178491\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.192667\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.108215\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.098893\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.244593\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.104685\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.314829\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.167607\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.260651\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.211360\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.110147\n",
            "Epoch: 25/40... Step: 7450... Train Loss: 0.075699... Val Loss: 0.242407\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.133228\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.177528\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.155944\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.165303\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.138242\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.239214\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.204208\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.275796\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.115972\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.277118\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.249113\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.080548\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.206345\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.128996\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.149347\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.112354\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.148763\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.220981\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.200520\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.225399\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.096019\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.206760\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.255192\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.121189\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.151917\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.131018\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.093209\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.132311\n",
            "Epoch: 25/40... Step: 7500... Train Loss: 0.063426... Val Loss: 0.102191\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.144003\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.217720\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.190324\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.076163\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.152876\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.073408\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.098709\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.340670\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.141953\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.210994\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.210381\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.239876\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.097964\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.173936\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.219282\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.122022\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.157298\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.107014\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.113382\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.081883\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.169512\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.137945\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.297300\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.115289\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.116664\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.199452\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.085914\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.186725\n",
            "Epoch: 25/40... Step: 7550... Train Loss: 0.115142... Val Loss: 0.198393\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.186733\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.103983\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.209056\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.229119\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.131117\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.268593\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.139403\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.103065\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.110439\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.095841\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.118206\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.177586\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.187947\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.250978\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.120269\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.143134\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.320329\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.329320\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.131286\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.206928\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.150847\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.368689\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.261342\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.130748\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.158936\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.252603\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.176767\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.324369\n",
            "Epoch: 25/40... Step: 7600... Train Loss: 0.103199... Val Loss: 0.204238\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.235748\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.206953\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.162606\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.170304\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.081423\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.297045\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.136115\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.188195\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.097085\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.252820\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.224628\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.179739\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.191073\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.098692\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.131517\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.191939\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.133748\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.221822\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.203353\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.116996\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.106002\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.136149\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.134670\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.140484\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.242360\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.344038\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.294538\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.190309\n",
            "Epoch: 25/40... Step: 7650... Train Loss: 0.053461... Val Loss: 0.183439\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.170975\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.199927\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.199837\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.275163\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.272071\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.151655\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.164657\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.143518\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.153669\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.163125\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.092779\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.189880\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.338627\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.257792\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.094698\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.382560\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.276528\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.229220\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.183549\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.123323\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.362334\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.240371\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.168205\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.235919\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.228229\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.166226\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.163015\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.159094\n",
            "Epoch: 25/40... Step: 7700... Train Loss: 0.159176... Val Loss: 0.139792\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.185820\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.363574\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.303538\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.207416\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.081581\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.334337\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.185637\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.125018\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.260252\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.150636\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.175234\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.157626\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.109846\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.196124\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.137895\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.091861\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.091399\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.160756\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.274837\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.249884\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.208425\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.265787\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.185128\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.186168\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.115551\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.194921\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.189971\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.171090\n",
            "Epoch: 26/40... Step: 7750... Train Loss: 0.039273... Val Loss: 0.240668\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.214538\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.193766\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.332553\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.115427\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.188301\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.200338\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.205597\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.233005\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.124043\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.403685\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.127354\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.159716\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.202307\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.183626\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.105963\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.238061\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.175615\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.220290\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.112920\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.161059\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.175995\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.125075\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.348661\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.293640\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.206426\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.478973\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.225509\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.149754\n",
            "Epoch: 26/40... Step: 7800... Train Loss: 0.152665... Val Loss: 0.150444\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.180294\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.106737\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.082121\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.184501\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.148521\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.474923\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.267318\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.157454\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.181227\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.103826\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.177875\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.225851\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.191939\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.168369\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.163424\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.114050\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.201747\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.183013\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.162904\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.121423\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.181012\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.123759\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.216841\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.241421\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.180571\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.075314\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.154630\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.063104\n",
            "Epoch: 26/40... Step: 7850... Train Loss: 0.048168... Val Loss: 0.100030\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.250315\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.118673\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.125449\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.237169\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.171764\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.176228\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.201606\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.184216\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.093963\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.112850\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.251233\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.180183\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.153121\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.179097\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.243956\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.119721\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.344635\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.267225\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.217286\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.187951\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.357305\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.098446\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.240286\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.247588\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.117167\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.178952\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.169512\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.107802\n",
            "Epoch: 26/40... Step: 7900... Train Loss: 0.093428... Val Loss: 0.139483\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.093330\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.229991\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.200756\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.274865\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.291096\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.172743\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.253257\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.130120\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.086691\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.178736\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.147520\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.247840\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.157316\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.173521\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.177118\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.132591\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.245818\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.213334\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.213762\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.072640\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.215047\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.229389\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.216164\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.112654\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.129674\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.125378\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.237669\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.351905\n",
            "Epoch: 26/40... Step: 7950... Train Loss: 0.057039... Val Loss: 0.239363\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.148118\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.151876\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.279588\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.216981\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.119610\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.192271\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.302684\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.184823\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.093690\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.249264\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.197130\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.205111\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.175314\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.082435\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.123560\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.109663\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.221187\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.200657\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.116060\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.118001\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.239558\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.177161\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.119482\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.128914\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.283855\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.141178\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.102378\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.174563\n",
            "Epoch: 26/40... Step: 8000... Train Loss: 0.096430... Val Loss: 0.091064\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.186544\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.215854\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.078575\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.218334\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.157982\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.177779\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.122860\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.232370\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.259529\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.314598\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.098196\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.157008\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.086435\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.179848\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.233573\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.115094\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.264547\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.182112\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.140949\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.166738\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.123966\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.177053\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.086282\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.192643\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.190761\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.267704\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.117456\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.112372\n",
            "Epoch: 27/40... Step: 8050... Train Loss: 0.065067... Val Loss: 0.200445\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.182134\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.119249\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.142456\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.170978\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.328665\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.267186\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.172009\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.164281\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.215835\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.144431\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.112821\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.171942\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.125040\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.505749\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.173886\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.140483\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.171722\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.112871\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.193747\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.068290\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.097939\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.254545\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.300656\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.296431\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.096315\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.175207\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.136030\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.134705\n",
            "Epoch: 27/40... Step: 8100... Train Loss: 0.044716... Val Loss: 0.150021\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.183937\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.074999\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.275457\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.186930\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.377700\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.100522\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.196497\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.177828\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.094309\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.170968\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.126100\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.167224\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.148870\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.086530\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.304865\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.387064\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.267481\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.094942\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.117787\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.105936\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.128820\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.213169\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.132430\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.121034\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.202584\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.104392\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.094431\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.216484\n",
            "Epoch: 27/40... Step: 8150... Train Loss: 0.034632... Val Loss: 0.305433\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.186201\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.203823\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.235657\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.210786\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.120967\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.148285\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.110909\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.132398\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.161155\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.114638\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.181915\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.150325\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.230313\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.150776\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.233670\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.100062\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.134597\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.131515\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.085708\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.165565\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.133538\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.165664\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.237553\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.288341\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.157913\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.149258\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.095964\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.161913\n",
            "Epoch: 27/40... Step: 8200... Train Loss: 0.057266... Val Loss: 0.130238\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.110716\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.155747\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.228464\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.079826\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.102604\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.091681\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.240997\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.119008\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.201197\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.093402\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.158233\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.279280\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.190530\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.107546\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.233510\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.181453\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.211561\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.164578\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.177891\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.224408\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.157630\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.091628\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.080299\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.162912\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.128835\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.126458\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.185938\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.097512\n",
            "Epoch: 27/40... Step: 8250... Train Loss: 0.068176... Val Loss: 0.135997\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.161629\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.120315\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.245514\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.231246\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.164604\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.186048\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.141552\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.149624\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.203176\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.289244\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.070060\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.164470\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.163406\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.140767\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.150669\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.189731\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.256533\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.123829\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.106315\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.134357\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.144777\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.064082\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.105203\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.138346\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.367373\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.124852\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.172531\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.088890\n",
            "Epoch: 27/40... Step: 8300... Train Loss: 0.078718... Val Loss: 0.183211\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.241101\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.200003\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.262612\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.135660\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.127474\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.129354\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.198843\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.215495\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.080603\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.096360\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.066042\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.299990\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.132848\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.222796\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.126857\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.132407\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.066694\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.212926\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.118664\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.104504\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.204524\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.081745\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.177165\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.148338\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.237998\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.280207\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.121887\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.219586\n",
            "Epoch: 28/40... Step: 8350... Train Loss: 0.059227... Val Loss: 0.098686\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.248022\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.290455\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.207639\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.150437\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.194978\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.158728\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.183192\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.247653\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.206791\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.159351\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.185787\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.066771\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.233638\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.139869\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.097940\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.042808\n",
            "Validation loss decreased (0.049406 --> 0.042808).  Saving model ...\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.168915\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.186432\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.331223\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.107859\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.094749\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.177227\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.104903\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.081321\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.107239\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.307543\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.069184\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.321909\n",
            "Epoch: 28/40... Step: 8400... Train Loss: 0.082067... Val Loss: 0.115968\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.123758\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.124302\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.223102\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.227610\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.183388\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.161929\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.088016\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.071271\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.247088\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.174447\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.160857\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.119252\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.137577\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.123922\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.149976\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.142560\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.180047\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.225186\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.284991\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.086410\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.231048\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.137644\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.158687\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.176486\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.222809\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.133417\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.319844\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.326497\n",
            "Epoch: 28/40... Step: 8450... Train Loss: 0.045391... Val Loss: 0.216734\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.099492\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.259220\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.203169\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.165377\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.233080\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.058739\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.099227\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.325216\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.174951\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.346120\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.238982\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.215988\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.154485\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.189922\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.282727\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.185665\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.202528\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.173495\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.151432\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.272547\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.215596\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.098910\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.082991\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.139614\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.127090\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.280895\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.143966\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.172469\n",
            "Epoch: 28/40... Step: 8500... Train Loss: 0.056614... Val Loss: 0.131583\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.152379\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.250431\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.151717\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.186396\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.156970\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.120736\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.099018\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.124608\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.193171\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.193689\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.150154\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.154567\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.289918\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.132987\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.198224\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.302772\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.210461\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.165044\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.299333\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.146513\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.121729\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.091738\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.121391\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.213639\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.216192\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.198237\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.105060\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.161067\n",
            "Epoch: 28/40... Step: 8550... Train Loss: 0.053622... Val Loss: 0.078453\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.122697\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.137912\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.197752\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.097354\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.448545\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.151129\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.147128\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.252145\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.134712\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.107574\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.130860\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.132437\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.135521\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.305259\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.164243\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.133910\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.193445\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.148017\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.194720\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.274725\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.164303\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.139145\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.196714\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.256320\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.266879\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.124695\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.140241\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.151233\n",
            "Epoch: 28/40... Step: 8600... Train Loss: 0.033094... Val Loss: 0.113609\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.129449\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.159818\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.164518\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.054934\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.194890\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.160124\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.223131\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.147582\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.142812\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.240481\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.118638\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.167909\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.118983\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.203114\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.127150\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.101219\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.086421\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.138997\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.157708\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.244891\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.077651\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.141100\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.164797\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.142405\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.104043\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.164723\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.219411\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.183826\n",
            "Epoch: 29/40... Step: 8650... Train Loss: 0.082874... Val Loss: 0.279415\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.235623\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.194425\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.201977\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.126467\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.130901\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.086841\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.106716\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.114287\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.226564\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.207515\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.240771\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.221545\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.153781\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.159202\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.096468\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.145347\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.117862\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.140221\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.137774\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.135623\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.178877\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.149853\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.073564\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.153071\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.174908\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.127344\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.211703\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.079731\n",
            "Epoch: 29/40... Step: 8700... Train Loss: 0.072891... Val Loss: 0.129843\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.089371\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.137190\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.174101\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.083646\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.117970\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.143469\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.273936\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.282452\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.113181\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.133573\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.110681\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.127709\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.199366\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.097131\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.276084\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.185361\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.183793\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.160879\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.213901\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.132500\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.194887\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.307008\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.121932\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.241405\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.173319\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.106724\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.134070\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.125633\n",
            "Epoch: 29/40... Step: 8750... Train Loss: 0.067014... Val Loss: 0.289485\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.123587\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.191085\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.183955\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.108489\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.176435\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.167588\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.159998\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.179684\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.120255\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.147414\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.145757\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.107780\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.216704\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.125797\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.078498\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.170708\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.196926\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.126806\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.188924\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.226014\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.201073\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.133375\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.251446\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.152604\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.190697\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.115634\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.254714\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.095619\n",
            "Epoch: 29/40... Step: 8800... Train Loss: 0.078126... Val Loss: 0.194875\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.283108\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.237291\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.124928\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.173243\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.115662\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.138538\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.177196\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.095289\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.083782\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.166623\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.207869\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.163227\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.261468\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.136240\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.264519\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.181110\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.108657\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.123860\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.135312\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.143206\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.129061\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.090529\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.101302\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.181237\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.197033\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.088454\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.308700\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.108632\n",
            "Epoch: 29/40... Step: 8850... Train Loss: 0.054818... Val Loss: 0.127536\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.147516\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.289791\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.145134\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.146627\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.191940\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.398062\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.156625\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.169121\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.207001\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.141125\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.189437\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.187456\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.129530\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.099557\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.094545\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.151333\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.208416\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.085682\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.213336\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.123501\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.254073\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.194482\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.153717\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.150736\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.155622\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.111738\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.113442\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.089817\n",
            "Epoch: 29/40... Step: 8900... Train Loss: 0.089248... Val Loss: 0.237079\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.188149\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.136222\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.112293\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.146948\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.130126\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.264357\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.160445\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.146103\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.120003\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.268142\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.155676\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.330748\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.220044\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.152055\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.197174\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.098912\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.100429\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.118048\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.046988\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.070365\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.149166\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.250387\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.180036\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.258506\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.243317\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.108478\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.086491\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.172504\n",
            "Epoch: 30/40... Step: 8950... Train Loss: 0.055889... Val Loss: 0.231764\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.126865\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.194544\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.104313\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.183268\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.264230\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.137549\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.283423\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.156095\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.137228\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.206726\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.181486\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.311528\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.106953\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.198707\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.160193\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.236117\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.225132\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.160534\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.208937\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.137650\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.225309\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.123650\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.154263\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.148484\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.175039\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.357933\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.308334\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.309791\n",
            "Epoch: 30/40... Step: 9000... Train Loss: 0.050235... Val Loss: 0.132480\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.165128\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.171559\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.232210\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.202613\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.103283\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.153591\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.289026\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.182011\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.194914\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.092010\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.135500\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.129990\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.291848\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.157613\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.210301\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.166204\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.309576\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.178294\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.116253\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.212454\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.108198\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.136476\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.118808\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.352650\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.147965\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.153050\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.124901\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.181837\n",
            "Epoch: 30/40... Step: 9050... Train Loss: 0.062348... Val Loss: 0.116146\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.106913\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.162021\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.157406\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.139292\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.269361\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.112041\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.139830\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.175004\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.065092\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.199951\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.132370\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.198037\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.136310\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.159440\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.158562\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.146085\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.363680\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.170439\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.209992\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.239782\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.168318\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.330366\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.216709\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.203434\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.161274\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.183042\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.302723\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.076954\n",
            "Epoch: 30/40... Step: 9100... Train Loss: 0.054550... Val Loss: 0.121398\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.174901\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.142019\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.200443\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.157144\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.123092\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.255192\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.126022\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.101184\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.303987\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.228244\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.108435\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.172517\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.127452\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.199429\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.091324\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.201542\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.323432\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.150817\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.233019\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.153807\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.163542\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.291395\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.210029\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.218505\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.272362\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.111604\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.141423\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.235479\n",
            "Epoch: 30/40... Step: 9150... Train Loss: 0.052156... Val Loss: 0.148149\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.153470\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.121503\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.145158\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.157003\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.124121\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.162520\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.094104\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.327016\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.227891\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.169511\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.163158\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.144681\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.172971\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.154828\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.146037\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.119536\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.079582\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.233898\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.265863\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.253064\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.206054\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.076674\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.115775\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.134654\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.272312\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.204434\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.226304\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.159955\n",
            "Epoch: 30/40... Step: 9200... Train Loss: 0.112785... Val Loss: 0.090146\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.242872\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.141303\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.207268\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.217454\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.093032\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.107315\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.196709\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.183866\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.167727\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.229266\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.161731\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.107085\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.102666\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.186469\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.061457\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.105143\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.074210\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.174687\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.168749\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.119924\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.117866\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.118043\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.147785\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.191163\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.121037\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.112821\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.239238\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.067681\n",
            "Epoch: 31/40... Step: 9250... Train Loss: 0.106339... Val Loss: 0.257901\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.284172\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.103480\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.133277\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.147823\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.228676\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.192834\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.106526\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.121240\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.135059\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.138103\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.134952\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.163653\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.176117\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.196535\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.139419\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.138803\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.107605\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.269926\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.153175\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.101369\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.205387\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.196258\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.135756\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.295230\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.193062\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.121563\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.266338\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.137048\n",
            "Epoch: 31/40... Step: 9300... Train Loss: 0.054201... Val Loss: 0.178595\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.194895\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.196488\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.259574\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.211555\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.138661\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.120006\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.184339\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.228297\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.147487\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.174818\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.176650\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.360339\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.080282\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.135777\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.179619\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.135649\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.280483\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.279300\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.086965\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.140392\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.255817\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.116955\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.106438\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.108089\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.109614\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.233438\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.083971\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.119060\n",
            "Epoch: 31/40... Step: 9350... Train Loss: 0.088235... Val Loss: 0.129554\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.198289\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.134254\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.308840\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.265031\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.183061\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.284051\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.090224\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.262145\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.211683\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.125453\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.164618\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.157084\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.079251\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.113417\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.149997\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.138566\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.182925\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.297946\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.115224\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.133511\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.160929\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.095886\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.287347\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.203584\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.094874\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.162945\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.124801\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.094604\n",
            "Epoch: 31/40... Step: 9400... Train Loss: 0.112900... Val Loss: 0.190791\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.198075\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.332032\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.248535\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.140211\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.158525\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.123676\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.159938\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.104017\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.200417\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.236484\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.140563\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.144880\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.219620\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.073719\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.274651\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.141002\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.142665\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.181900\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.224158\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.094488\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.170597\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.156202\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.163815\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.109404\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.260074\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.170160\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.084967\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.135101\n",
            "Epoch: 31/40... Step: 9450... Train Loss: 0.037281... Val Loss: 0.263590\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.094974\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.275269\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.229099\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.166683\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.148624\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.308244\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.182036\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.174872\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.111516\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.111778\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.306207\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.195643\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.121861\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.102110\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.254942\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.146939\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.173801\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.071994\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.183054\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.097031\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.134309\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.351158\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.080006\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.137407\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.102655\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.269674\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.080062\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.189574\n",
            "Epoch: 31/40... Step: 9500... Train Loss: 0.090961... Val Loss: 0.196013\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.105919\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.152235\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.179682\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.113610\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.099983\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.118396\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.121011\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.261534\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.139801\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.226227\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.294220\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.181875\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.187514\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.105185\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.189015\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.142786\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.166616\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.101229\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.098799\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.137307\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.114093\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.283362\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.196321\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.236469\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.141872\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.087173\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.112276\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.100472\n",
            "Epoch: 32/40... Step: 9550... Train Loss: 0.054697... Val Loss: 0.190879\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.140931\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.144530\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.084337\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.147062\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.231367\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.317120\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.184507\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.161557\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.192871\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.208592\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.264547\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.129597\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.251449\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.178829\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.225579\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.117997\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.219214\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.213955\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.236986\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.132166\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.137531\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.165300\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.239226\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.157509\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.222571\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.388350\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.121168\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.151688\n",
            "Epoch: 32/40... Step: 9600... Train Loss: 0.063554... Val Loss: 0.267046\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.118526\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.114678\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.257392\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.201190\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.124912\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.129961\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.099258\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.231355\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.305597\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.164709\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.161976\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.218013\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.161305\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.251960\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.135607\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.299404\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.159291\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.089341\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.146716\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.144909\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.248449\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.143328\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.253918\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.206148\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.106981\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.221186\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.099618\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.089098\n",
            "Epoch: 32/40... Step: 9650... Train Loss: 0.046773... Val Loss: 0.269725\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.111464\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.203958\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.113385\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.117233\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.074536\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.140985\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.245660\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.186309\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.143948\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.291622\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.113765\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.199638\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.307353\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.205435\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.299115\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.117735\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.172803\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.111782\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.297442\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.163686\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.134157\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.098621\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.088950\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.171409\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.202233\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.124688\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.117505\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.142648\n",
            "Epoch: 32/40... Step: 9700... Train Loss: 0.084964... Val Loss: 0.098578\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.098880\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.139214\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.113470\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.115039\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.135266\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.167543\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.211763\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.084067\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.157211\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.100637\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.160244\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.216673\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.230375\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.191509\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.119405\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.199149\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.115935\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.161209\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.375935\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.087947\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.153378\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.159064\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.260594\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.146307\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.147942\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.142172\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.218691\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.094013\n",
            "Epoch: 32/40... Step: 9750... Train Loss: 0.099019... Val Loss: 0.192862\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.144595\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.102002\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.166391\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.089753\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.210334\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.289807\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.170513\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.256059\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.103740\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.214583\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.148292\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.121174\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.137373\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.193096\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.246830\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.105054\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.217855\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.207993\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.135670\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.300534\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.187146\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.079975\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.163088\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.105127\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.155849\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.199615\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.132080\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.173152\n",
            "Epoch: 32/40... Step: 9800... Train Loss: 0.070761... Val Loss: 0.306438\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.181279\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.131253\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.139744\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.143084\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.168667\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.163641\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.154536\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.147157\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.235285\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.172351\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.137796\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.261695\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.228176\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.081201\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.315264\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.170500\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.148829\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.124975\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.234230\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.168829\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.148816\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.083898\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.205020\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.317781\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.185124\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.131894\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.121992\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.125642\n",
            "Epoch: 32/40... Step: 9850... Train Loss: 0.044019... Val Loss: 0.170732\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.126169\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.109650\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.169760\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.155503\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.245272\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.122315\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.206246\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.213237\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.248444\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.139096\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.164665\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.103167\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.203629\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.257286\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.099929\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.155692\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.178446\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.071530\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.105002\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.100561\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.169091\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.307207\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.117870\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.137975\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.117766\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.151494\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.111159\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.093225\n",
            "Epoch: 33/40... Step: 9900... Train Loss: 0.077675... Val Loss: 0.130531\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.306366\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.120184\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.227333\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.111313\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.249055\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.144860\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.188888\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.085522\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.332703\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.081885\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.111723\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.195039\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.213974\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.250949\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.152988\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.133061\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.119844\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.136222\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.140870\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.108048\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.095623\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.110020\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.089547\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.217814\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.176263\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.098590\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.266248\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.101750\n",
            "Epoch: 33/40... Step: 9950... Train Loss: 0.069804... Val Loss: 0.156718\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.096332\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.242092\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.072378\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.279154\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.220616\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.211732\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.102955\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.153912\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.138713\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.146591\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.265226\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.127134\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.155211\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.151606\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.115939\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.145641\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.133308\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.090673\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.087400\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.144365\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.117310\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.180934\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.120034\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.247949\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.096905\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.155610\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.288726\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.252185\n",
            "Epoch: 33/40... Step: 10000... Train Loss: 0.059662... Val Loss: 0.124408\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.114160\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.176469\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.212438\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.188503\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.187140\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.107740\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.173005\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.149673\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.150466\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.132276\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.067603\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.155418\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.092546\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.134288\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.186952\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.168480\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.215792\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.221876\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.247038\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.132099\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.133962\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.280812\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.176740\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.117145\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.181123\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.107523\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.169861\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.090506\n",
            "Epoch: 33/40... Step: 10050... Train Loss: 0.037453... Val Loss: 0.298013\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.269241\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.167735\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.085798\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.208717\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.123722\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.256881\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.194878\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.146243\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.179198\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.170101\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.159408\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.077335\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.267059\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.130151\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.262931\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.198686\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.092675\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.214119\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.155191\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.234617\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.185918\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.079215\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.312320\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.235005\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.102014\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.090870\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.119624\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.084074\n",
            "Epoch: 33/40... Step: 10100... Train Loss: 0.094171... Val Loss: 0.201306\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.077044\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.147203\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.185167\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.147343\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.225815\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.182141\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.171097\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.213509\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.118710\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.235695\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.213972\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.175906\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.186158\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.240565\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.144176\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.120886\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.112639\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.153472\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.105023\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.134428\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.145293\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.124430\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.114488\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.279801\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.118346\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.133703\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.139003\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.116900\n",
            "Epoch: 33/40... Step: 10150... Train Loss: 0.081847... Val Loss: 0.056739\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.249300\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.108262\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.113731\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.154044\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.122742\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.192751\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.133313\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.227595\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.263810\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.236023\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.311558\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.111763\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.144923\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.215616\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.106623\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.401988\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.164595\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.166873\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.180638\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.145597\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.097870\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.128430\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.190467\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.104840\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.173345\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.127094\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.252898\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.135001\n",
            "Epoch: 34/40... Step: 10200... Train Loss: 0.085998... Val Loss: 0.131161\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.195207\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.065086\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.251115\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.224087\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.244996\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.062913\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.096108\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.159269\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.146145\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.196118\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.282294\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.095719\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.204114\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.189089\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.212124\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.192006\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.109380\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.117081\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.131502\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.168893\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.088389\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.203356\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.293803\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.124293\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.329114\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.169930\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.137201\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.145874\n",
            "Epoch: 34/40... Step: 10250... Train Loss: 0.102448... Val Loss: 0.114966\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.182990\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.109686\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.078211\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.082853\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.148868\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.172368\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.212128\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.094576\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.163560\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.140583\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.229779\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.155028\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.278034\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.089077\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.078149\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.292359\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.321299\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.122686\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.094958\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.149655\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.108264\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.181138\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.316908\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.158608\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.223499\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.183380\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.118666\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.075067\n",
            "Epoch: 34/40... Step: 10300... Train Loss: 0.080219... Val Loss: 0.099684\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.181391\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.149141\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.110229\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.208239\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.144115\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.155746\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.131835\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.125647\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.137343\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.278389\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.206184\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.138504\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.186705\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.124116\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.282990\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.202634\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.286200\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.124138\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.159815\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.227583\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.213328\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.139819\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.100797\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.093661\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.185896\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.273684\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.179401\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.102565\n",
            "Epoch: 34/40... Step: 10350... Train Loss: 0.058883... Val Loss: 0.101760\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.146768\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.240096\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.196789\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.236294\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.234322\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.152471\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.102903\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.102690\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.168874\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.126696\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.117165\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.148327\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.088296\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.172883\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.074848\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.175097\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.137315\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.248848\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.147791\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.087697\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.105909\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.337292\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.188076\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.117212\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.099022\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.098029\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.149438\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.153168\n",
            "Epoch: 34/40... Step: 10400... Train Loss: 0.076261... Val Loss: 0.088459\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.202483\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.123485\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.285808\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.121327\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.115389\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.201081\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.119739\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.161009\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.135470\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.142712\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.150461\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.155217\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.149675\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.136792\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.135516\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.145500\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.120985\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.276895\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.141507\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.275855\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.269145\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.257847\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.178197\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.132671\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.097069\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.160432\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.098729\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.085513\n",
            "Epoch: 34/40... Step: 10450... Train Loss: 0.047397... Val Loss: 0.088757\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.085884\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.132037\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.229737\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.237927\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.160595\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.253119\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.182083\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.230637\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.069573\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.147846\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.148616\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.069654\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.153183\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.258441\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.161305\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.243467\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.121035\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.146844\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.136736\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.228397\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.155853\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.159262\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.120025\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.172511\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.182952\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.236057\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.167186\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.208459\n",
            "Epoch: 35/40... Step: 10500... Train Loss: 0.077429... Val Loss: 0.211517\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.158774\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.177271\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.222794\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.127502\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.139213\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.213638\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.176728\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.138607\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.115653\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.083766\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.132602\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.194776\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.106461\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.321070\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.276983\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.179514\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.133017\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.121343\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.180117\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.192663\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.231261\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.301294\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.518953\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.113635\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.162832\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.159898\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.155348\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.130892\n",
            "Epoch: 35/40... Step: 10550... Train Loss: 0.067613... Val Loss: 0.166467\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.143883\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.209925\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.046669\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.078850\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.225721\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.096076\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.171287\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.242317\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.197147\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.099911\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.062655\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.065104\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.209306\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.303918\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.155825\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.194900\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.224333\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.117595\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.191459\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.071977\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.050930\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.141103\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.120300\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.294668\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.165983\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.086664\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.242900\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.183189\n",
            "Epoch: 35/40... Step: 10600... Train Loss: 0.075309... Val Loss: 0.111983\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.108644\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.117194\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.192562\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.289207\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.133460\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.232224\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.134264\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.113823\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.255049\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.199972\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.152942\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.269193\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.214584\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.161074\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.111481\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.202560\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.179037\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.062760\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.148042\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.261767\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.163742\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.107375\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.095528\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.091748\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.092787\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.169382\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.120897\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.115083\n",
            "Epoch: 35/40... Step: 10650... Train Loss: 0.053605... Val Loss: 0.149950\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.183521\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.185031\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.099597\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.115632\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.174323\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.125640\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.081942\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.216401\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.098207\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.180320\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.296506\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.238436\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.163445\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.269898\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.142716\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.146591\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.102796\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.294210\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.104909\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.140923\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.161758\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.254206\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.154064\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.111282\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.286352\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.265531\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.132438\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.337169\n",
            "Epoch: 35/40... Step: 10700... Train Loss: 0.041267... Val Loss: 0.203528\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.178802\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.093131\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.096613\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.225553\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.161266\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.085254\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.190654\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.167899\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.272460\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.133909\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.263358\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.222421\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.147685\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.230263\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.155631\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.124282\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.100991\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.106110\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.119130\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.104376\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.138417\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.203346\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.125197\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.116209\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.108248\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.223479\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.107560\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.119640\n",
            "Epoch: 35/40... Step: 10750... Train Loss: 0.084348... Val Loss: 0.115867\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.144298\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.241504\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.191117\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.100667\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.145423\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.068361\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.160572\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.147212\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.153441\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.093700\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.273649\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.211071\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.096617\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.145376\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.203437\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.131565\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.128888\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.087029\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.077131\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.162246\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.134045\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.235612\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.322678\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.302613\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.112339\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.291484\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.186820\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.112005\n",
            "Epoch: 36/40... Step: 10800... Train Loss: 0.041066... Val Loss: 0.106133\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.101589\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.101038\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.158380\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.264298\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.166515\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.233077\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.154591\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.170367\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.103748\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.195954\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.072244\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.086295\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.166803\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.152963\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.281019\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.180259\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.209209\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.054625\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.105363\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.186048\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.138154\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.232826\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.266966\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.177352\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.134072\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.126020\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.315693\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.161676\n",
            "Epoch: 36/40... Step: 10850... Train Loss: 0.095347... Val Loss: 0.108335\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.111617\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.192073\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.183289\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.115854\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.084990\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.123302\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.237100\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.128605\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.146184\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.299993\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.252301\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.170894\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.155984\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.099866\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.127381\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.069647\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.141636\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.108939\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.301499\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.200511\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.321816\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.105241\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.139186\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.129872\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.239041\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.125651\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.138092\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.186265\n",
            "Epoch: 36/40... Step: 10900... Train Loss: 0.071024... Val Loss: 0.183613\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.170363\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.146722\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.280603\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.151528\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.128893\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.130982\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.315253\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.171122\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.251320\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.212170\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.188464\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.140888\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.145013\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.344381\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.091458\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.158493\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.161257\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.141061\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.127107\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.162200\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.183266\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.089955\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.184771\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.164121\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.205009\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.208276\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.249829\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.119383\n",
            "Epoch: 36/40... Step: 10950... Train Loss: 0.028208... Val Loss: 0.130964\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.265722\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.112886\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.127576\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.165645\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.141527\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.098437\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.133648\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.198663\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.123713\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.100782\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.101862\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.279478\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.099957\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.214546\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.156365\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.180980\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.150995\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.367795\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.119635\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.163696\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.162996\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.136145\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.083367\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.207443\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.153120\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.154141\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.096890\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.084002\n",
            "Epoch: 36/40... Step: 11000... Train Loss: 0.076105... Val Loss: 0.070860\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.165041\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.123406\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.170225\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.278403\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.159303\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.180539\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.143821\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.158248\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.101673\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.174317\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.137387\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.286249\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.202934\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.139345\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.279878\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.151871\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.137125\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.147218\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.185249\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.173275\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.196755\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.282159\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.164456\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.225022\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.255196\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.343469\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.088213\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.136445\n",
            "Epoch: 36/40... Step: 11050... Train Loss: 0.060177... Val Loss: 0.202355\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.151681\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.171318\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.150790\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.197097\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.136450\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.197534\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.236326\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.183078\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.157464\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.262873\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.110528\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.247948\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.170298\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.335670\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.107046\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.263005\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.213515\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.151476\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.150971\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.254574\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.127834\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.110393\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.095429\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.160437\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.192161\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.108696\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.177266\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.085679\n",
            "Epoch: 37/40... Step: 11100... Train Loss: 0.065052... Val Loss: 0.305089\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.081405\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.116789\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.148276\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.172381\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.266906\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.255312\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.226023\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.127180\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.169257\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.133910\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.165578\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.417279\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.239420\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.096939\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.180752\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.108857\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.309461\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.130387\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.191695\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.208467\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.152613\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.139808\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.203723\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.116834\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.196259\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.128439\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.109914\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.157354\n",
            "Epoch: 37/40... Step: 11150... Train Loss: 0.065680... Val Loss: 0.145879\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.090223\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.201680\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.227405\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.279633\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.121789\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.211740\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.137997\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.163309\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.112096\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.143451\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.131951\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.510169\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.205368\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.121136\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.159690\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.143890\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.189151\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.125756\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.364091\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.157238\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.163345\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.239710\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.081186\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.186509\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.184410\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.053450\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.119988\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.177564\n",
            "Epoch: 37/40... Step: 11200... Train Loss: 0.085717... Val Loss: 0.110612\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.213103\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.098858\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.114261\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.241242\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.127662\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.213143\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.114391\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.191975\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.288299\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.151033\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.131712\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.175023\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.157170\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.155786\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.126135\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.081535\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.252151\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.295852\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.136602\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.144303\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.181098\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.188209\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.434766\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.155816\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.203597\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.143065\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.178304\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.200260\n",
            "Epoch: 37/40... Step: 11250... Train Loss: 0.053719... Val Loss: 0.165806\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.108625\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.156154\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.100793\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.122055\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.099288\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.084971\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.116553\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.291033\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.163532\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.156684\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.208314\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.153305\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.139898\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.072768\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.179608\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.189640\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.094372\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.162707\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.187302\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.315524\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.075347\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.198276\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.197327\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.221487\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.143048\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.158531\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.116145\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.123137\n",
            "Epoch: 37/40... Step: 11300... Train Loss: 0.040927... Val Loss: 0.181880\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.136966\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.097867\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.150222\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.188789\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.111622\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.153891\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.091232\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.067104\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.147797\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.193638\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.125612\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.392125\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.105431\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.235905\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.150920\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.166888\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.166691\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.171604\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.125748\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.113653\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.202179\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.078736\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.107782\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.347213\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.185322\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.181555\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.119311\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.138885\n",
            "Epoch: 37/40... Step: 11350... Train Loss: 0.048862... Val Loss: 0.120823\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.131490\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.194516\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.090872\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.078028\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.232000\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.140287\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.128106\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.185144\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.114922\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.085828\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.072443\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.229238\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.183848\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.173734\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.150891\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.153782\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.108596\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.214394\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.158741\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.272086\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.137345\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.105345\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.139886\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.174575\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.125113\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.292519\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.192009\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.199140\n",
            "Epoch: 38/40... Step: 11400... Train Loss: 0.118594... Val Loss: 0.095157\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.125777\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.150969\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.118728\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.277717\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.130479\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.285280\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.130046\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.168790\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.154215\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.159718\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.190052\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.146357\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.136194\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.192199\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.068432\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.184054\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.087728\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.110008\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.191569\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.130021\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.315387\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.110335\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.217720\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.103161\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.190460\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.117464\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.098232\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.146209\n",
            "Epoch: 38/40... Step: 11450... Train Loss: 0.065358... Val Loss: 0.115863\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.146252\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.314591\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.281237\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.193049\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.181641\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.153783\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.100782\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.186960\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.142719\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.119334\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.145824\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.113364\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.128388\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.191232\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.137755\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.180695\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.159393\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.140733\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.097879\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.222065\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.254548\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.159969\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.189716\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.213696\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.176984\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.133221\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.103126\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.172483\n",
            "Epoch: 38/40... Step: 11500... Train Loss: 0.031835... Val Loss: 0.211344\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.178186\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.180951\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.190237\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.284087\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.160384\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.119716\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.103656\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.123754\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.075613\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.111723\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.240806\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.207246\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.133023\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.068984\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.269588\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.184792\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.260247\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.164708\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.119188\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.181098\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.165221\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.134858\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.260475\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.095572\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.145811\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.153327\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.183030\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.200191\n",
            "Epoch: 38/40... Step: 11550... Train Loss: 0.070751... Val Loss: 0.125679\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.107625\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.072196\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.130231\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.323455\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.099912\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.190336\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.139184\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.071198\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.111726\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.125425\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.137295\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.094745\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.210411\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.210851\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.147229\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.147284\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.117826\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.282915\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.215235\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.076423\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.156159\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.319993\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.117305\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.133122\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.276986\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.154223\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.225049\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.127077\n",
            "Epoch: 38/40... Step: 11600... Train Loss: 0.044048... Val Loss: 0.074126\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.115289\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.097328\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.201147\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.262822\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.109144\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.122909\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.135318\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.264310\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.111026\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.152156\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.167391\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.159951\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.108787\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.236675\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.127715\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.298184\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.186381\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.147031\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.108688\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.172503\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.139560\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.219966\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.104343\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.122511\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.119791\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.262132\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.207893\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.189446\n",
            "Epoch: 38/40... Step: 11650... Train Loss: 0.084374... Val Loss: 0.199598\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.165663\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.176227\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.120297\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.322292\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.106561\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.361804\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.153670\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.070819\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.140774\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.122421\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.330881\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.110209\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.178629\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.082728\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.177312\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.138285\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.258255\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.204353\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.119481\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.109027\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.129172\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.239949\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.317417\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.122940\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.135102\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.124635\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.079777\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.100365\n",
            "Epoch: 38/40... Step: 11700... Train Loss: 0.045769... Val Loss: 0.066961\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.108355\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.199270\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.133246\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.128238\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.152413\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.195044\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.184114\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.136100\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.174899\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.161853\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.189034\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.204191\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.059836\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.142189\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.185660\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.114546\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.165686\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.150435\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.136581\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.112613\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.178186\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.148484\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.113111\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.193214\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.235138\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.242747\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.095655\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.149627\n",
            "Epoch: 39/40... Step: 11750... Train Loss: 0.048662... Val Loss: 0.252855\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.188898\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.072693\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.137957\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.236455\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.223294\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.183829\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.078352\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.194161\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.222762\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.190389\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.096628\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.173216\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.097848\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.142154\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.161438\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.065640\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.107314\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.203672\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.187108\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.168538\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.188224\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.094819\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.120701\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.134882\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.170949\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.251867\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.086183\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.141616\n",
            "Epoch: 39/40... Step: 11800... Train Loss: 0.047139... Val Loss: 0.130984\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.137599\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.212322\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.245917\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.132803\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.151365\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.302414\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.116722\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.130361\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.117652\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.114034\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.192565\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.166790\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.222119\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.436797\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.156248\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.127054\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.186527\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.146993\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.074674\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.093131\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.076167\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.184251\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.167108\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.086060\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.129778\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.098653\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.113377\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.139903\n",
            "Epoch: 39/40... Step: 11850... Train Loss: 0.057659... Val Loss: 0.062531\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.189060\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.192161\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.138825\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.172781\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.245050\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.271297\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.361571\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.270407\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.131074\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.163812\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.131631\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.143091\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.139994\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.288688\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.106715\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.123406\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.225556\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.130954\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.151342\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.130312\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.093120\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.150860\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.094185\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.110360\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.177536\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.092752\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.127783\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.131360\n",
            "Epoch: 39/40... Step: 11900... Train Loss: 0.046911... Val Loss: 0.125217\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.320455\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.142130\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.246528\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.189849\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.243464\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.171324\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.130806\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.130967\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.229286\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.119242\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.163024\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.103009\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.117719\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.203727\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.142110\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.174255\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.160153\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.262492\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.192441\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.121356\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.307581\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.138893\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.104476\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.222112\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.184970\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.170979\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.321430\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.146443\n",
            "Epoch: 39/40... Step: 11950... Train Loss: 0.087139... Val Loss: 0.093933\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.111614\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.077653\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.223054\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.280306\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.164105\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.114024\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.069284\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.156835\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.180381\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.081834\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.160781\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.065060\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.126074\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.100188\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.089148\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.098716\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.213971\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.240667\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.137366\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.130555\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.219889\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.288550\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.064782\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.237248\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.202736\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.116525\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.123717\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.106178\n",
            "Epoch: 39/40... Step: 12000... Train Loss: 0.041550... Val Loss: 0.182380\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.111288\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.137097\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.177462\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.289431\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.105952\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.287151\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.139371\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.142380\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.118538\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.138681\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.165712\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.173113\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.165493\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.075411\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.161182\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.148347\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.214504\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.111774\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.130089\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.085685\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.122734\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.114806\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.140963\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.201848\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.100899\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.272391\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.224891\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.082006\n",
            "Epoch: 40/40... Step: 12050... Train Loss: 0.049652... Val Loss: 0.163733\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.188653\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.107417\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.106606\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.216569\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.265345\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.156399\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.186854\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.273981\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.210003\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.175156\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.263763\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.086929\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.140009\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.292932\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.081779\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.177143\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.188182\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.190461\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.134748\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.189579\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.120416\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.277935\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.088134\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.221566\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.183346\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.123904\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.144284\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.229316\n",
            "Epoch: 40/40... Step: 12100... Train Loss: 0.059691... Val Loss: 0.075249\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.219277\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.144921\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.269052\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.080868\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.185557\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.105185\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.250603\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.139931\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.172214\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.085401\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.142660\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.106039\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.220513\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.211694\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.151106\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.172729\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.358347\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.085756\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.155251\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.159385\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.085336\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.094331\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.252144\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.117715\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.145058\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.112024\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.152643\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.095597\n",
            "Epoch: 40/40... Step: 12150... Train Loss: 0.058664... Val Loss: 0.064899\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.285210\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.083220\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.194978\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.129284\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.081733\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.179907\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.184631\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.087752\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.146329\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.353036\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.263199\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.195824\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.115338\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.212331\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.088282\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.128600\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.244954\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.095912\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.253561\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.192718\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.082653\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.122105\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.113620\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.109358\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.079633\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.132376\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.242812\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.234759\n",
            "Epoch: 40/40... Step: 12200... Train Loss: 0.033951... Val Loss: 0.106236\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.103917\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.162839\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.158919\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.262870\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.122964\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.221092\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.201927\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.093695\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.273137\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.142571\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.248873\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.256488\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.136487\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.136181\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.121621\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.141686\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.126204\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.167931\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.340238\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.094676\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.096269\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.105603\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.227873\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.103976\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.221551\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.120737\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.156333\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.121113\n",
            "Epoch: 40/40... Step: 12250... Train Loss: 0.055287... Val Loss: 0.135886\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.112845\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.115803\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.172062\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.205577\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.205211\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.203840\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.175660\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.189502\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.123050\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.180218\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.142415\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.112616\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.181090\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.110614\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.079128\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.114552\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.258903\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.126205\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.125116\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.085321\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.262563\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.077681\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.213147\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.151617\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.166810\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.143453\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.125488\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.160658\n",
            "Epoch: 40/40... Step: 12300... Train Loss: 0.085547... Val Loss: 0.277966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_kCWAcWDrhYx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot training and validation losses"
      ]
    },
    {
      "metadata": {
        "id": "aMoKa95uqUof",
        "colab_type": "code",
        "outputId": "e89f59a2-867a-454d-b0df-3f8cb8a22c49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(losses['train'], label='Training loss')\n",
        "plt.plot(losses['validation'], label='Validation loss')\n",
        "plt.legend()\n",
        "_ = plt.ylim()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuQAAAH4CAYAAAACWPgYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1bqOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 370,
              "height": 252
            }
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "z-7aS5_yIems",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# If you don't want to train continue with below code\n",
        "\n",
        "Load the dictionary to model and continue with plotting results"
      ]
    },
    {
      "metadata": {
        "id": "5wPYzSZzAqVi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load dictionary to network"
      ]
    },
    {
      "metadata": {
        "id": "6r8O3bnZAwWK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('drive/My Drive/Colab Notebooks/colabArchives/model_soloupis_bikeShare_PR1.pt')\n",
        "net.load_state_dict(state_dict['state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MHdHLz4wtnqs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Get test data loss"
      ]
    },
    {
      "metadata": {
        "id": "ZsD09eMftqNs",
        "colab_type": "code",
        "outputId": "7ebe4079-4a5d-4864-a992-605f1bb1d6e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "test_acc_list = []\n",
        "\n",
        "test_losses = [] # track loss\n",
        "\n",
        "# init hidden state\n",
        "h = None\n",
        "\n",
        "net.eval()\n",
        "### We move to cpu so to use later output for plotting\n",
        "net.cpu()\n",
        "net.double()\n",
        "for batch_i, (inputs, labels) in enumerate(test_loader, 1):\n",
        "\n",
        "    # make sure you iterate over completely full batches, only\n",
        "    n_batches = len(test_loader.dataset)//batch_size_test\n",
        "    #print(n_batches)\n",
        "    if(batch_i > n_batches):\n",
        "        break\n",
        "    \n",
        "    print(batch_i)\n",
        "\n",
        "    ## pass inputs through net\n",
        "    output, test_h = net(inputs.unsqueeze(1), h)\n",
        "    ##take a look at first output and label\n",
        "    print(\"OUTPUT    \",output[0,:])\n",
        "    print(\"LABEL    \",labels[0,:])\n",
        "    \n",
        "    ### We don't update weights at testing  \n",
        "    \n",
        "    # calculate the loss   \n",
        "    test_loss = criterion(output, labels)\n",
        "    test_losses.append(test_loss.item())\n",
        "    print(\"TEST LOSSES : {}\".format(test_losses))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "OUTPUT     tensor([0.2205, 0.2957, 0.2016], dtype=torch.float64, grad_fn=<SliceBackward>)\n",
            "LABEL     tensor([-0.2396, -0.3585, -0.1704], dtype=torch.float64)\n",
            "TEST LOSSES : [0.19441172167121057]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "16e0S5JjuAqN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot real data and predictions"
      ]
    },
    {
      "metadata": {
        "id": "PENxbE1GuA8s",
        "colab_type": "code",
        "outputId": "c0971609-1099-49a2-9597-49174946b602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(8,4))\n",
        "\n",
        "mean, std = scaled_features['cnt']\n",
        "##plot real data\n",
        "ax.plot((test_targets['cnt']*std + mean).values, label='Data')\n",
        "\n",
        "##make tensor to numpy\n",
        "output = output.detach().numpy()\n",
        "## we get the first values of the output as these are the 'cnt' predictions\n",
        "ax.plot(output[:][:,:1]*std + mean, label='Prediction')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "dates = pd.to_datetime(rides.loc[test_data.index]['dteday'])\n",
        "dates = dates.apply(lambda d: d.strftime('%b %d'))\n",
        "ax.set_xticks(np.arange(len(dates))[12::24])\n",
        "_ = ax.set_xticklabels(dates[12::24], rotation=45)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8kAAAIXCAYAAACvjxxyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngiAIFv8fBmIn4M+72aAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 484,
              "height": 267
            }
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "fhZB1kG09Z6D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the diagram we can see major difference in holiday period.The model is a bit overfitted to correctly classify the holiday period. One reasonable answer is the model fails to generalize the Christmas period (aka Holiday period) because it has seen this period only once before (Dec 2011)."
      ]
    },
    {
      "metadata": {
        "id": "T1myhedYI2NJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## IF YOU WANT TO START FROM THE BEGGINING USE BELOW CODE"
      ]
    },
    {
      "metadata": {
        "id": "JViof8pbHPkF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}